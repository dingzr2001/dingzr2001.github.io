{"posts":[{"title":"AdaDelta and Adam Algorithm","text":"AdaDelta and Adam AlgorithmAdaDeltaAdaDelta is another variant of AdaGrad. Like RMSProp, it solves the problem of relying too much on previous gradients, by leaky average, but in a more complicated way. Here is how it works. First, like RMSProp, we have:$$S_t=\\rho S_{t-1} + (1-\\rho)g_t^2$$but unlike RMSProp, we don’t upgrade W directly with S. We have a iterative equation:$$\\begin{cases}M_t = \\rho M_{t-1}+(1-\\rho)G_{t-1}^2\\G_t = \\frac{\\sqrt{M_{t-1}+\\epsilon}}{\\sqrt{S_t+\\epsilon}}\\cdot g_t\\end{cases}$$If we combine them into one equation, we have:$$G_t=\\frac{\\sqrt{\\rho M_{t-2}+(1-\\rho)G_{t-1}^2+\\epsilon}}{\\sqrt{S_t+\\epsilon}}\\cdot\\nabla W_t$$And we update W with G:$$W_t = W_{t-1} - G_t$$The iterative equation part could be quite confusing. The sequence of calculation and update should be: gradient($g_t=\\nabla W_t$) $S_t$ $G_t$ $M_t$ $W_t$ In AdaDelta, we have no learning rate $\\eta$, that means we don’t need to set a hyper-parameter by ourselves. AdamWe use a algorithm to combine RMSProp and momentum method.$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t$$ $$v_t = \\beta_2 v_{t-1}+(1-\\beta_2)g_t^2$$ It is suggested that we set $\\beta_1$ to 0.9 and $\\beta_2$ to 0.999. To correct the discrepancy between the expectation of v and $g_t^2$, we need to correct the v:$$\\hat{v_t}=\\frac{v_t}{1-\\beta_2^t}$$Likewise, we could also correct m by:$$\\hat{m_t}=\\frac{m_t}{1-\\beta_1^t}$$And now we could update W by:$$W_t=W_{t-1}-\\eta\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t}}+\\epsilon}$$About the correction of discrepancy part, the author gives a inference in the original paper:https://arxiv.org/pdf/1412.6980v9.pdf? YogiWe can rewrite the formula in Adam to:$$v_t=v_{t-1}+(1-\\beta_2)(g_t^2-v_{t-1})$$If the gradient is too big, Adam algorithm may fail to converge. To fix this problem, we have Yogi algorithm:$$v_t=v_{t-1}+(1-\\beta_2)g_t^2\\cdot sgn(g_t^2-v_{t-1})$$ Referenceshttps://arxiv.org/pdf/1412.6980v9.pdf? https://zh-v2.d2l.ai/d2l-zh-pytorch.pdf https://blog.csdn.net/weixin_35344136/article/details/113041592 https://blog.csdn.net/ustbbsy/article/details/106930309","link":"/2023/02/18/AdaDelta-and-Adam-Algorithm/"},{"title":"From C# and Python -- A Deep Dive into Language Execution and Typing Models","text":"From C# and Python: A Deep Dive into Language Execution and Typing ModelsOne day I was asked about the difference between C# and Python. Then I realized that many people still has misunderstadings for some concepts in programming language. Starting from the question “What’s the difference between C# and Python”, I will dive into the principle of compilers and interpreters, to elaborate on this issue. Code Execution: From Traditional to Modern ApproachesThe Traditional Distinction: Compiled vs. InterpretedProgramming languages are traditionally categorized by how their code is translated and executed. Compiled Languages (e.g., C, C++): A compiler translates the entire program’s source code into a standalone executable file containing machine code before it is run.1 This one-time process produces highly optimized code that is executed directly by the computer’s CPU, resulting in fast performance. However, this also means the compiled code is specific to a particular machine architecture, and every change to the source code requires a new compilation step. Interpreted Languages (e.g., early JavaScript): An interpreter reads and executes the source code line by line at runtime.1 This process does not create a separate executable file. This allows for a fast development cycle, as a developer can run the code immediately after writing it.1 However, the continuous, on-the-fly translation makes interpreted languages generally slower than compiled languages.2 Feature Compiled Languages Interpreted Languages Translation Entire program translated at once. Translated and executed line-by-line. Execution Speed Fast, due to pre-translation. Slower, due to continuous translation. Error Handling All syntax errors found before execution. Errors found as they are encountered. Development Cycle Slower (edit, compile, run). Faster (edit, run). How Compilers Translate Source Code into Executable FileAlthough different compilers may have different steps, we will use the most standard compiled language: C, and its most commonly taught compiler: clang for example. 1. Preprocessing Tool: clang -E (if run separately) Expands #include headers, macro definitions, and conditional compilation (#ifdef, #if, etc.). The output is a single, pure C/C++ source file with all macros resolved. 2. Lexical Analysis (Tokenization) Removes comments and whitespace Converts the character stream into a stream of tokens—keywords, identifiers, literals, operators, … 3. Syntax Analysis (Parsing) Builds an Abstract Syntax Tree (AST) from the token stream according to the C/C++ grammar. Detects syntax errors such as a missing semicolon or mismatched braces. 4. Semantic Analysis Performs type checking, scope resolution, overload resolution, and verifies language rules (e.g., correct function calls, conversions). Annotates the AST with type and symbol information. 5. LLVM IR Generation The validated AST is lowered into LLVM Intermediate Representation (IR)—a language-independent, SSA-based (Static Single Assignment) form. This is the boundary between the front end (Clang) and the LLVM core. 6. Optimization (LLVM Middle End) LLVM applies a series of target-independent optimizations to the IR: Constant folding, dead-code elimination, loop transformations, inlining, vectorization, etc. 7. Target Code Generation (LLVM Back End) The optimized IR is lowered to target-specific assembly (x86-64, ARM, etc.). The integrated assembler converts that assembly to a relocatable object file (.o). 8. Linking The system linker (ld or LLVM’s lld) combines object files and libraries, resolves symbols, and produces the final executable (e.g., hello). How Interpreters Translate Source Code1. Lexical Analysis 2. Syntax Analysis 3. Semantic Analysis (4. Translate to ByteCode) Some interpreter will translate AST from step 3 to bytecode (a kind of intermediate representation ) 5. Interpretation Run bytecode line by line or traverse AST We can see that one big difference is the semantic analysis. In compiled languages, the sematic analysis is run before IR generation, while in interpreted languages, there are no such steps. In interpreted languages, there indeed will be some checking before building an ATS, but that is just to make sure the structure of the ATS is legal. For example, if there is a missing bracket or parenthesis, this will prevent the interpreter from building a legal ATS. These errors will be reported, but other errors such as typing, naming error, will not be reported unless the code is run to that line. If you have tried to run a C# program, you will most likely use Visual Studio. After your program is completed, you will need to “build” a objective, and that is the compiling process of C#. After building, you will have an exe file that can be run immediately. Based on this characteristic, we generally categorize C# as a compiled language. 1.2 The Modern Hybrid Model: Bridging the GapIn fact, like most modern languages, C# and Python have something more than just the standard compiled and based language. The C# Hybrid Model: The C# compiler first translates source code into Intermediate Language (IL), which is a platform-independent set of instructions. When the program runs, the Common Language Runtime (CLR) uses a Just-In-Time (JIT) compiler to translate the IL into native machine code on demand. This dynamic process allows C# programs to achieve high performance while remaining portable across different operating systems and hardware. The Python Hybrid Model: When a Python script is executed, the interpreter first compiles the source code into a platform-independent bytecode. A Python Virtual Machine (PVM) then executes this bytecode, translating each instruction into machine code at runtime. This process is lightweight and enables Python’s fast development cycle. Both C# and Python use an intermediate representation and a virtual machine, but their implementation details differ. C#’s initial compilation is more thorough, enabling more powerful runtime optimizations from its JIT compiler, which contributes to its higher performance. Although technically they are all hybrid, they stiil possess the core feature that makes them compiled/interpreted languages. What are Different Typing Categories?Static vs. Dynamic Typing: The Timing of Type CheckingThe concepts of static and dynamic typing are about when type checking occurs. Static Typing: In a statically typed language, a variable’s type is checked by the compiler before the program runs. For a language like C#, you must declare the type, and it cannot change during execution. This catches type-related errors early, which is a major advantage for code reliability. C# Code Example: 12345// This works. The compiler knows 'myNumber' is an integer.int myNumber = 5;// This causes a 'compile-time' error. The compiler stops you.myNumber = &quot;hello world&quot;; Dynamic Typing: In a dynamically typed language, a variable’s type is checked at runtime. In Python, you do not declare a type; it is determined by the value assigned to it. This provides more flexibility but means type errors are only discovered when the code is executed. Python Code Example: Python 12345# This works. The interpreter knows 'myVariable' is a string.myVariable = &quot;hello world&quot;# This also works. The interpreter allows you to reassign the type.myVariable = 5 Strong vs. Weak Typing: The Rules of ConversionThe concepts of strong and weak typing relate to how a language handles conversions between different data types. Strong Typing: A strongly typed language has strict rules that prevent unsafe, implicit conversions. Both C# and Python are strongly typed languages. They will stop an operation if the types are incompatible, such as trying to add a string to a number. 12# This will throw an exception:print(&quot;aaa&quot; + 1) Weak Typing: A weakly typed language is more permissive and may automatically convert data types to perform an operation, which can lead to unpredictable results. # This will not throw an exception console.log(&quot;aaa&quot; + 1) It is a common misconception that static/dynamic typing is the same as strong/weak typing. They are two separate concepts. A language can be static and strong (C#), or dynamic and strong (Python). Chapter 3: The Relationship Between Execution and TypingThe type of a language’s execution model does not dictate its type system, and vice versa. For example, a traditional compiled language like C is statically typed but is often considered weakly typed due to its permissive rules on implicit conversions and pointer arithmetic. Conversely, a traditionally interpreted language like Python is dynamically typed but strongly typed because it strictly enforces type compatibility at runtime. Ultimately, the choice of a language’s execution model and type system represents a design trade-off between development speed and performance/safety. Static Typing leads to a slower development cycle but provides benefits like early error detection and greater performance due to compiler optimizations. Dynamic Typing allows for a faster development cycle and greater flexibility, but with the trade-off of catching errors at runtime and potential performance overhead from continuous type checks.","link":"/2025/09/19/A-Deep-Dive-into-Language-Execution-and-Typing-Models/"},{"title":"","text":"CUDA编程 2. Elementwise 本篇参考LeetCUDA的实现 Elementwise 操作Elementwise是一类算子的统称，所谓算子（Operator），就是一个执行特定数学运算的函数单元，可以类比数据库的Operator。 Elementwise类的算子特征就是每一个位置的元素只喝对应位置的元素进行计算，互不干扰，换句话说就是“位置对齐，各算各的”。因此，不难发现我们上一片中定义的vectorAdd核函数就是一个Elementwise算子。 下面让我们用一些例子来透彻理解Elementwise算子 Elementwise Add首先，对于普通的fp32的elementwise add，和我们上一篇写的vectorAdd是一样的。在此就不赘述了。 这个方法还可以进行优化，如下： 123456__global__ void elementwise_add_fp32x4(float *a, float *b, float *c, int numElements){ int idx = 4 * (blockDim.x * blockIdx.x + threadIdx.x); if (idx &lt; numElements){ float4 group_a = reinterpret_cast&lt;float4*&gt;(a) }} 关于向量化访存，可以参考这篇文章","link":"/2026/02/07/CUDAelementwise/"},{"title":"AdaGrad and RMSProp Algorithm","text":"AdaGrad and RMSProp AlgorithmAdaGradStandard gradient descend is too scaled to be applied to modern deep neural network. AdaGrad is a effective method to optimize by adjusting learning rate dynamically and automatically. At each step,$$S_t=S_{t-1}+\\nabla W_t\\cdot \\nabla W_t$$ $$W_t =W_{t-1}-\\frac{\\eta}{\\sqrt{S_t+\\epsilon}}\\nabla W_t$$ The more the weight vector has changed in a dimension, the more gradient it has accumulated on that dimension. In AdaGrad, we use $ S_t $ to count the gradient of W in the past, and update W with S. The bigger $ S_i $ is, the smaller the change on $ W_i $ would be. By doing this, we could adjust learning rate on each dimension respectively, according to the frequency and range of changes on each dimension of the weight vector. If your path has gone through a steep slope in the direction of X-axis, you need to slow down in X-axis in case you miss the terminal. But your path is quite flat in Y-axis, so you don’t need to slow down too much on that direction. RMSPropThe problem of AdaGrad is that it counts on gradients in the past too much, so that it might not respond timely on the sudden change of gradient. That is because S has accumulated too much previous gradient. We want to reduce the impact of the gradient too far away in the past, so here we have RMSProp Algorithm:$$S_t=\\gamma S_{t-1}+(1-\\gamma)\\nabla W_t\\cdot \\nabla W_t$$ $$W_t =W_{t-1}-\\frac{\\eta}{\\sqrt{S_t+\\epsilon}}\\nabla W_t$$ The only change is the weight $ \\gamma $ of $ S_{t-1} $. This makes the portion of previous gradients in current S decay in a growing rate. Referenceshttps://zh-v2.d2l.ai/d2l-zh-pytorch.pdf https://zhuanlan.zhihu.com/p/72039430 https://blog.csdn.net/rpsate/article/details/127320124 https://www.bilibili.com/video/BV1r64y1s7fU?spm_id_from=333.880.my_history.page.click","link":"/2023/02/17/AdaGrad-and-RMSProp-Algorithm/"},{"title":"Dijkstra 算法","text":"Dijkstra Algorithm迪杰斯特拉（按照读音，应该读作戴克斯特拉）算法是用于求解单源最短路径的经典算法。 单源最短路径问题在一个带权的图中，从某个特定的起始点（源）出发，计算到某个终点的最短路径，这种问题被称为单源最短路径问题。 Dijkstra算法思路Dijkstra算法基于贪心思想，具体思路为：维护一个“已确定”的顶点集合和“未确定”的顶点集合，用“已确定”的顶点对“未确定”集合中的顶点不断地更新，并把“未确定”的顶点一个个加入“已确定”集合，最终确定下所有的顶点的最短路径。 每一轮，在“未确定”的集合中选出距离源点路径最短的顶点A，把这个顶点确定下来加入到”已确定“顶点集合。原因是：这个点A的最短路径想要更新，必须要找到一个点B，它的路径更短，这样加上这个点到当前节点的边B-&gt;A，才有机会比当前A得最短路径更短。但是所有满足这种条件的A都已经被“确定“了，不能再用了，因为我们已经用过了。剩下“未确定”的点，最短都一定大于等于当前A得最短距离，那么肯定对A是帮不上忙的。 现在A被“确定”了，“已确定”点集又填新成员，就可以试试再用这个新成员来“帮助”未确定的顶点。具体而言，即遍历A直接指向的顶点，尝试用A得最短路径加上A到它们的距离，来更新它们的最短路径。如果dist(A)+edge&lt;A, B&gt;小于dist(B)，B的最短路径就可以变成先从源点走A的最短路径到A，再从A到B。这被称为一次“松弛”操作。这个词很有意思，想象两个节点由一根绳子连接，现在来了一根更短的绳子，使劲把它们连在一起，原来的绳子就松弛了。 如此循环这个操作，直到所有节点都被确定，整个图所有节点的单源最短路径就确定了。 条件刚才提到，为什么不用剩下的节点来更新A，是因为剩下的节点路径更长，对A帮不上忙。而这是基于一个前提，就是不存在负边权。如果存在负边权，这个更新逻辑就不成立了，整个Dijkstra算法就失效了。 优化在寻找“未确定”集合中的最小值时，如果每次都一个一个比较，太慢了。我们可以用小根堆（优先队列）来优化这个过程 例题LeetCode 743 网络延迟时间题目链接 题目描述： 有 n 个网络节点，标记为 1 到 n。 给你一个列表 times，表示信号经过 有向 边的传递时间。 times[i] = (ui, vi, wi)，其中 ui 是源节点，vi 是目标节点， wi 是一个信号从源节点传递到目标节点的时间。 现在，从某个节点 K 发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回 -1 。 123456789101112131415161718192021222324252627282930313233class Solution: def networkDelayTime(self, times: List[List[int]], n: int, k: int) -&gt; int: graph = dict() hp = [] final_vertices = set() # build graph for time in times: source, target, weight = time if source not in graph: graph[source] = [] graph[source].append([target, weight]) heapq.heappush(hp, (0, k)) max_dist = 0 # Dijkstra Algorithm while len(hp): dist, top = heapq.heappop(hp) if top not in final_vertices: # 这一步判断很重要，因为我们的优先队列中同一个顶点可能出现多次，但是一定只有最先遇到的才是最短的路径，剩下的直接丢掉就好 max_dist = dist if top in graph: for target, weight in graph[top]: # 对每个节点尝试执行“松弛”操作 if target not in final_vertices: heapq.heappush(hp, (dist + weight, target)) final_vertices.add(top) if len(final_vertices) == n: return max_dist return -1","link":"/2025/01/19/Dijkstra-Algorithm/"},{"title":"Binary Search All in One","text":"Binary Search All in One[Glad to hear that this article helped my friend prepare his interview and he solved a binary search problem quickly and accurately during a TikTok interview.] Even though there are many different types of binary search scenarios, almost every binary search problem can be reduced to the following paradigm: The whole array can be split into two parts (left and right). Left part complies with rule R Right part complies with rule $ \\neg R $ We need to find the first element of the second part, or the last element of the first part. The pseudo code for solving this problem can be: 1234567891011def binary_search(nums): length = len(nums) l, r = 0, length - 1 while l &lt;= r: mid = (l + r) &gt;&gt; 1 if R(nums[mid]): l = mid + 1 else: r = mid - 1 # return l if we are looking for the first element of the right part # return r if we are looking for the last element of the left part To elaborate on this piece of code: l, r are the endpoints of the array $ mid = (l + r) // 2 $ (find the middle point of the range [l, r]) if mid falls in the left part (follows rule R): the objective we are looking for is on the right side of mid, so $ l = mid + 1 $ else: objective is on the left side, $ r = mid - 1 $ When the loop ends, it is guaranteed that $ l == r + 1 $, and $ l $ will be the first element of the right part, $ r $ will be the last element of the last part. Note that in some test cases, the left or right part might not exist, i.e., their length is 0. There should be some special handles when the index is out of range Lets take several examples: 852. Peak Index in a Mountain Array You are given an integer mountain array arr of length n where the values increase to a peak element and then decrease. Return the index of the peak element. Your task is to solve it in O(log(n)) time complexity. The array can be split into two parts: left (uphill): $ arr[i] &gt; arr[i - 1] $ right (downhill): $ arr[i] &lt; arr[i - 1] $ The peak element we are looking for is the last element of left part. Hence the code is: 123456789101112class Solution: def peakIndexInMountainArray(self, arr: List[int]) -&gt; int: # find the first element that &lt; its previous element l = 0 r = len(arr) - 1 while l &lt;= r: mid = (l + r) &gt;&gt; 1 if mid &gt; 0 and arr[mid] &gt; arr[mid - 1]: l = mid + 1 else: r = mid - 1 return r 33. Search in Rotated Sorted Array There is an integer array nums sorted in ascending order (with distinct values). Prior to being passed to your function, nums is possibly left rotated at an unknown index k (1 &lt;= k &lt; nums.length) such that the resulting array is [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]] (0-indexed). For example, [0,1,2,4,5,6,7] might be left rotated by 3 indices and become [4,5,6,7,0,1,2]. Given the array nums after the possible rotation and an integer target, return the index of target if it is in nums, or -1 if it is not in nums. You must write an algorithm with O(log n) runtime complexity. The array can be split into two parts. left: arr[i] &gt;= arr[0] right: arr[i] &lt; arr[0] The approach is to first find out the boundary of these two parts, determine which part the target might belong to, and find if it exists in that part. The boundary actually falls between the last element of the left part and the first element of the right part, but we can take it this way: the right boundary of the left part is its last element, and the left boundary of the right part is its first element. After finding the boundary, we can determine the left part and right part. In each part, elements are strictly increasing. We can use another binary search to find out if the target is among one of them. 1234567891011121314151617181920212223242526272829class Solution: def search(self, nums: List[int], target: int) -&gt; int: length = len(nums) l, r = 0, length - 1 # find the boundary while l &lt;= r: mid = (l + r) &gt;&gt; 1 if nums[mid] &gt;= nums[0]: l = mid + 1 else: r = mid - 1 # determine which part the target might belongs to, adjust the range for searching accordingly if target &gt;= nums[0]: l, r = 0, r else: l, r = l, length - 1 # find the element in that range while l &lt;= r: mid = (l + r) &gt;&gt; 1 if nums[mid] == target: return mid elif nums[mid] &lt; target: l = mid + 1 else: r = mid - 1 return -1","link":"/2025/09/10/Binary-Search-All-in-One/"},{"title":"CUDA编程 1. GPU架构和入门程序","text":"GPU架构与CUDA编程了解GPU架构硬件元件：CUDA Core, SMNVidia GPU迭代了多种架构，有Tesla、Fermi、Maxwell、Kepler、Turing等，但是各种架构的核心结构是相似的。 我们都知道GPU善于做大量并行的、简单的运算，比如说矩阵运算。这就与GPU的架构有关了。CPU的架构注重复杂的控制逻辑和单条指令的低延迟（加入分支预测、冒险等），而GPU则注重高吞吐率，每个计算单元相对简单，由多个计算单元同时进行计算来达到极高的吞吐量。 这种执行模型叫做SIMT（Single Instruction Multiple Threads)，即单指令多线程，就是让大量的线程执行同一个运算指令，只不过操作的是不同的数据。 GPU的最小运算单元叫做SP（Streaming Processor)，在新的架构中又叫CUDA Core，本质上是一个标量ALU（算术逻辑单元）。 多个CUDA Core组成一个SM（Streaming Multiprocessor，流式多处理器)。不同架构的SM拥有不同数量的CUDA Core。CUDA Core专指单精度运算单元，处理的是FP32数据。除此之外，一个SM中还有双精度运算单元（DPU），处理FP64数据，以及特殊功能单元（SFU），处理特殊数学函数如sin, cos, log, sqrt等，还有张量核心（Tensor Core）。 SM中除了这些元件外，还包括寄存器、共享内存、Warp调度器。为了理解这些元件的关系，我们从线程的结构讲起。 线程：Thread, Warp, Block和GridGPU是SIMT模型，也就是说，对于一个指令，会拆分成多个线程（thread），每个线程跑在CUDA Core上（这里和CPU是相似的），同一时间一个线程跑在一个CUDA Core上。然而，GPU不直接操作thread，而是把32个thread打包成一个Warp（线程束）。Warp是GPU硬件调度与执行的最小单位，也就是说，一条指令必须分配32的倍数个线程，每个Warp内的线程 多个Warp可以组成一个Thread Block（线程块，简称Block），这个线程块是在软件视角下的一个逻辑结构。一个Block包含若干个线程，这些线程会自动被切割为若干个Warp，例如如果定义的Block大小是128，那么就会被分为4个Warp。每个Block被分配给一个SM，这个Block的整个生命周期就在这个SM上度过，但是一个SM可以有一个或多个Block，只要SM的寄存器和共享内存够用。 然而，SM的执行单元是不认识Block的，它只认识Warp。SM会维护一个就绪队列，由Warp调度器来调度Warp，如果一个Warp就绪并且有足够的空闲CUDA Core，调度器就会把Warp交给CUDA Core执行。 那么Block的意义是什么呢？尽管SM的执行单元只调度Warp，但是SM的控制单元是认识Block的，它会为每个Block分配单独的一片共享内存，这片内存在Block内是共享的，但是和其他Block是隔离的。Block的存在意义就是为了更好地做线程同步。 从CUDA编程的角度，一个Block是一个线程的“三维容器”，可以看作是一个三维数组，它的维度用dim3结构来定义，例如： 12345678// 一维Blockdim3 blockSize(256, 1, 1);// 二维Blockdim3 blockSize(16, 16, 1);// 三维Blockdim3 blockSize(16, 4, 4); 这里block的不同维度其实只是为了语义上易读，类似CPU中的N维数组，虽然看起来是N维的，但是事实上是按照1维展开寻址的。 而一个“核函数“启动的所有block的集合就称为一个Grid。 CUDA编程CUDA是基于C++的扩展，在C++的基础上，引入了一些特殊关键字和类/结构/函数。为了让指令在GPU上运行，我们需要写一个核函数，并且用Host代码也就是CPU代码来调用这个核函数，类似一个系统调用。 从最简单开始，我们先写一个A+B的函数：将A、B数组按位相加并写入数组C。 头文件依赖12#include &lt;iostream&gt;#include &lt;cuda_runtime.h&gt; //CUDA运行时库 编写Kernel（核函数）要放到CUDA Core（核）上运行的函数就是核函数。 123456__global__ void vectorAdd(const float *A, const float *B, float *C, int length){ int idx = blockDim.x * blockIdx.x + threadIdx.x; if (idx &lt; length) { C[idx] = A[idx] + B[idx]; }} 解读一下： 1__global__ void vectorAdd(const float *A, const float *B, float *C, int length); 这里的__global__关键字是CUDA核函数的专用关键字，用于告知编译器这个函数由CPU调用，在GPU上执行。 1int idx = blockDim.x * blockIdx.x + threadIdx.x; 这行代码就有意思了。这个核函数不是会分为多个线程执行吗，每个线程就只操作数组中的一位。那么每个线程的编号就是它前面的所有Block的所有线程数加上它在当前Block中的位置。想象我们在二维数组中给每个元素编号，是不是这样： 1int idx = i * N + j; 这里是类似的道理，blockDim.x是每个Block容器的大小，blockIdx是当前Block的索引，threadIdx.x是当前线程在Block中的索引。当然这里只考虑比较简单的一维情况，更高维度的情况会在后续章节中讨论。 编写Main函数现在我们写好了要在GPU上运行的Kernel，但是这个Kernel怎么调用呢？因此我们还需要写一个Main函数（Host代码）调用它。 123456789101112131415161718192021222324252627282930313233343536373839404142int main(){ const int numElements = 10000; size_t size = numElements * sizeof(float); // 给数组分配的内存 float *h_A = (float *)malloc(size); float *h_B = (float *)malloc(size); float *h_C = (float *)malloc(size); // 此处省略初始化 //在显存中开辟三个数组 float *c_A = NULL; float *c_B = NULL; float *c_C = NULL; cudaMalloc((void **)&amp;c_A, size); cudaMalloc((void **)&amp;c_B, size); cudaMalloc((void **)&amp;c_C, size); // 把数据从CPU内存搬运到显存 cudaMemcpy(c_A, h_A, size, cudaMemcpyHostToDevice); cudaMemcpy(c_B, h_B, size, cudaMemcpyHostToDevice); int threadsPerBlock = 256; int blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock; //向上取整 // 启动核函数 vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(c_A, c_B, c_C, numElements); // 把运算结果搬回CPU内存 cudaMemcpu(h_C, c_C, size, cudaMemcpyDeviceToHost); // 整套运算完成，可以检查结果 // 释放显存和内存 cudaFree(c_A); cudaFree(c_B); cudaFree(c_c); free(h_A); free(h_B); free(h_C); return 0;} 这段代码还算比较清晰明了，唯一要注意的是启动核函数那里： 1vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(c_A, c_B, c_C, numElements); 这个是一个固定格式：函数名&lt;&lt;&lt;Grid数, Block数&gt;&gt;&gt;(参数...)，这里的blocksPerGrid会被写入到一个**只读特殊寄存器（SREG）**中，这样在核函数中取blockDim，就是去读这个寄存器。如果blocksPerGrid被定义为int，就等价于定义为一个一维的dim3对象。如果想要多维的block，就可以定义：dim3 blockSize(16, 16);并在vectorAdd中传入这个参数。这个我们后面会再遇到的。 至此我们就写完了最简单的一个CUDA程序。","link":"/2026/02/07/GPU%E6%9E%B6%E6%9E%84%E4%B8%8ECUDA%E7%BC%96%E7%A8%8B/"},{"title":"&lt;note&gt;Tiresias：Enabling Predictive Autonomous Storage and Indexing","text":"Tiresias：Enabling Predictive Autonomous Storage and IndexingHighlightsThe main innovation is the ability to predict future access patterns based on past data accesses and proactively adjust storage structures and indexes to accommodate new transactional or analytical demands. Specifically, through training, Tiresias learns: ① temporal patterns of access ② latency prediction functions. Tiresias only provides a judgment on whether the layout should change based on current and predicted conditions, without actually performing the layout change. Applications Adjusting storage structures in Proteus based on HTAP workload Transactions are split into operators (storage-specific) to facilitate prediction; Here, “operators” mean units formed by splitting transactions according to storage structures and workload. For example, a transaction may be decomposed into the following four operators: ① Send request to data site ② Acquire lock ③ Row-level update ④ Commit The paper does not specify how operators are derived Tiresias is used to record operator latencies and data access logs Predict the timing and frequency of new data accesses The last two steps are supported via APIs Predictive cracking on OLAP DBMS Predict workload changes and adjust data storage Automatic indexing in PostgreSQL Record query arrival history, latencies, and existence of secondary indexes (indexes not on primary keys) Predict query types, latencies, and secondary indexes Use Tiresias predictions to add or remove secondary indexes ImplementationData Access Latency PredictionSplit a transaction into multiple connected operators, compute the loss function for each operator and sum them Input: a1,…,an, parameters extracted from operators according to storage structures and workload Loss function F: Linear regression: fast and low latency Non-linear regression Neural network (MLP) Collect current latencies: capture start/end times and data read/write details (total size of read/write columns), each thread maintains an observation structure storing all latencies for each pair, then aggregate for training Data Access PredictionPredict when and how frequently data will be accessed Predict $δ(T, \\tau)$, the number of requests of type T arriving in a time window at $\\tau$ SPAR PredictorTwo components: Long-term periodic changes: Hourly, daily, or yearly patterns. First set how many past periods $\\psi_n$ to consider, take δ values from previous $\\psi_n$ periods and weight them with learnable weights bi. Short-term variations: Change in a short period relative to previous periods. According to the formula in the paper: This compares the access volume in a time window at a point with the same window i periods ago (1 ≤ i ≤ $\\psi_n$). For example, if request volume follows a sine pattern and $\\tau$ is at a trough, the formula computes the difference between the current window’s access volume and the average of previous $\\psi_n$ troughs. This measures changes relative to previous periods. Then sum the weighted γ values of consecutive $\\psi_k$ points. Together with the long-term periodic formula, this predicts periodic variations in access volume. In a sine function example, it captures differences in access volume between the current $\\psi_k$ interval and the same interval $\\psi_k$ periods ago, allowing SPAR to learn features like “each sine cycle has a wave-shaped decline”. Add this to the long-term prediction to obtain δ. Hybrid-Ensemble PredictorThree components: Long-term periodic change: LSTM Short-term change: Linear regression User-defined holiday list: specify start/end time and Gaussian parameters, compute access if current time falls within the period Access History Each partition records per-minute access volumes, collected in a round-robin manner for training SPAR: previous $\\psi_n$ periods stored in circular buffer HE: uses LSTM but Tiresias still keeps long-term history Evaluating Benefits of Layout and Index ChangesFor a layout change S, consider two parts: Cost of layout change: U(S) Cost difference before and after change (benefit) Use predictors to estimate transaction latency Lcurrent and Ladapt for current and new layout Compute C(S): cost function of current requests Compute Pr(T): probability of type T arriving at time τ Compute Δ(T): time until next type T request Compute E(S, T): expected cost of a request at a given time E depends on relative latency changes, request probability, and expected arrival time. If currently processing type T request, Pr(T)=1, Δ(T)=0, so E(S,T)=C(S), the difference between current and adapted layout latencies $L_{current}-L_{adapt}$ Finally, combine: $N(S) = \\lambda (E(S)+C(S))-U(S)$ λ adjusts the relative weight. Only if N&gt;0 (benefit exceeds cost) is layout change considered profitable. ExperimentsDatasets CH-benCHmark: TPC-C OLTP + TPC-H OLAP Transactional YCSB workload: 10 multi-key read-modify-write + 1 scan (5e5 rows) OLAP aggregation queries Access Cost Estimator ComparisonLinear regression training is 1500x and 2500x faster per round than neural network and non-linear regression, respectively. Accuracy is slightly lower but sufficient for judging change benefit. Initial linear regression accuracy is higher, enabling fast workload adaptation. Access Predictor ComparisonSPAR is more accurate, but poorly chosen periods increase error. Predictions are noisier but memory efficient. PostgreSQL Auto-Indexing ResultsWorkload changes at 5, 10, 15 minutes Comparison: PostgreSQL+Tiresias, PostgreSQL with indexes, PostgreSQL without indexes: Tiresias index selection reduces completion time by 70% and 15% compared to no index and static indexes. OLAP: indexing fastest; OLTP: indexing increases update cost, reducing throughput. Tiresias dynamically adjusts: OLAP speed comparable to indexing, OLTP speed comparable to no indexing. Source Codehttps://github.com/mtabebe/Adaptive-Storage-Tiresias-and-Proteus/tree/master 中文原文 亮点主要的创新点是能够根据过去的对数据的访问预测未来的访问趋势，提前做出存储结构和索引的变化以适应新的事务或分析需求，即：通过训练，学习①访问的时间规律②访问的延迟预测函数。Tiresias只是根据当前和预测的情况，给出判断：是否应该改变布局，而不执行具体的改变布局的操作。 应用 Proteus中根据HTAP负载调整存储结构 把事务拆分成操作符（storage-specific），方便预测； 这里的操作符意思是：根据存储结构和工作负载对事务进行拆分形成的单元，比如对于某个事务，分解成以下四个操作符： ① 向数据站点发送请求 ② 获取锁 ③ 按行更新 ④ 提交 文中并未提及操作符是怎么得来的 调用Tiresias记录操作符延迟和数据访问记录 预测新的数据访问到来的时间和频率 最后两步都有API 在OLAP DBMS上的predictive cracking 预测workload变化，改变数据存储 PostgreSQL上的自动索引 记录查询的到达历史、延迟和是否有二级索引（不在主键上创建的索引） 预测查询类型、延迟和是否有二级索引 根据Tiresias的预测，添加或去除二级索引 实现数据访问延迟预测将一个事务拆分成多个相连的操作符，对这些操作符分别计算损失函数再相加 输入：a1，…，an，是将一个操作符（operator）参数化，根据存储结构和工作负载提取的参数。 损失函数F： 线性回归：（因为速度快延迟小被采用） 非线性回归 神经网络（MLP） 采集当前的延迟：采集起止时间和数据读写情况（读写列的总大小等），每个线程有一个observation数据结构，把每一个 &lt;存储结构-操作符&gt; 对应的所有latency保存为一个list，最后汇总在一起，用于训练 数据访问预测预测数据何时将要被以什么频次访问 预测 $δ(T, \\tau)$，表示类型 T 的请求在 $\\tau$ 时的一个时间窗口内到来的数量 SPAR预测器包含两部分： 长期周期性变化： 每个小时、每天或者每年的规律。首先设定好要回顾多少个周期，$\\psi _n$，考虑 前 $\\psi _n$ 个周期的 δ 值，对它们进行加权，权重 bi 需要学习 短期内变化： 某一个短周期访问量相比于之前周期的变化。此处较难理解。首先看论文给出的公式： 这个公式表示，对于某一个点，比较他的时间窗口内访问量i个周期前(1 ≤ i ≤ $\\psi_n$)的对应点的窗口。比如说考虑请求量随时间按照正弦函数分布，如果 $\\tau$ 时间在波谷，那么该公式就是将 $\\tau$ 时刻的窗口内的访问量减去前 $\\psi_n$ 个波谷的窗口内的访问量的平均值。通过该公式衡量当前点与之前周期的对应点的访问量的变化。 然后将连续 $\\psi_k$ 个点的 γ 值加权求和。 这两个公式结合在一起，意义是预测周期内的访问量变化的周期性。仍然以正弦函数为例，这个函数表征的就是$\\psi_k$长度内访问量与n个周期之前$\\psi_k$长度的区间内访问量有何差异。随着时间推移，通过这个公式，SPAR学习到的就是 “每个周期正弦函数都会有一个波浪形的下坡” 这个特征。 然后把这个式子和上面长期周期性变化的式子加起来得到 δ 的预测值 Hybrid-Ensemble预测器包含三部分： 长期周期性变化： LSTM 短期变化： 线性回归 用户自定义holiday list 设定起止时间和高斯函数(正态分布的概率密度)的参数，如果当前时间在起止时间之间，就用高斯函数计算访问量 访问历史 每个分区记录一分钟的访问量，轮询收集，将收集到的访问量用于训练 SPAR：采集前 $\\psi_n$ 周期的数据存在环形缓冲区内 HE：使用LSTM，但是Tiresias仍需要保存长期的历史记录 评估存储结构和索引变化的获利对于存储布局的改变S，考虑两部分： 改变布局本身的消耗： U(S) 改变布局前后的消耗对比（收益） 对于当前结构和改变后的结构，分别使用相应的预测器预测事务的延迟Lcurrent和Ladapt 计算C(S)：当前请求的消耗函数 计算时间 $\\tau$ 时到达T类型指令的可能性Pr(T) 计算到下一个T类型指令到来需要的时间Δ(T) 计算E(S, T)：在某一时间预期请求的消耗函数 E决定于延迟的相对变化、请求到来的可能性、请求到来的时间（估计值） 特别地，如果当前正在处理该类型请求，那么Pr(T) = 1, Δ(T) = 0，带入就是C(S)，也就是当前结构对于当前类型请求的延迟和改变后结构对当前类型请求的延迟的差值 $L_{current}-L_{adapt}$ 最后综合这两部分 $N(S) = \\lambda (E(S)+C(S))-U(S)$ λ用于调控两者之间的相对权重 也就是说只有：在λ权重下，改变布局带来的收益大于改变布局本身的损失，即 N &gt; 0，才会认为改变布局是可以获利的 实验数据集 CH-benCHmark：包含TPC-C OLTP workload和TPC-H OLAP workload 事务型YCSB workload：10个多键读取-修改-写入事务+1个扫描（5e5行）聚合OLAP查询 访问开销估计器对比线性回归每轮训练耗时比神经网络和非线性回归分别快1500倍和2500倍，尽管精确度稍微低一些，但是对于判断改变的好坏还是足够了 线性回归初始精度更高，这样正好可以快速适应负载。 访问预测器对比SPAR精度更高，但是如果周期数设定不合理误差反而会大很多。预测的更易变（毛糙，因为会从之前的预测中继承噪音）空间开销小 PostgreSQL自动索引效果workload在5、10、15分钟会发生变化 比较了PortgreSQL+Tiresias, 有索引的PostgreSQL和无索引的PostgreSQL，结果为： 使用Tiresias的索引选取相比于不加索引和加索引，workload完成时间分别快了70%和15% OLAP情况下，加索引最快，但是加索引会导致更新开销变大，因此OLTP情况下，加索引吞吐率最低，而Tiresias由于可以动态调整，因此在OLAP下与加索引速度相当，OLTP下速度与不加索引相当。 源代码https://github.com/mtabebe/Adaptive-Storage-Tiresias-and-Proteus/tree/master","link":"/2023/06/28/Tiresias/"},{"title":"Milvus, A Purpose-Built Vector Data Management System","text":"Milvus: A Purpose-Built Vector Data Management SystemAuthor: Jianguo Wang ,et al. vector database A new type of database specialized in storing and querying vector data. Traditional relational databases: precise attribute-based searches Vector database: approximate similarity-based vector searches: find the k-nearest vectors to the query. Background &amp; Motivation ChallengesCurrent works have the following limitations: They are not full-fledged systems and cannot handle large amount of data They cannot easily handle dynamic data while ensuring fast real-time searches They do not support advanced query processing They are not optimized for heterogeneous computing architecture with CPUs and GPUs MilvusMilvus: a purpose-built vector data management system for managing large-scale and dynamic vector data to enable data science and AI applications. Milvus incorporates query processing, indexing and storage management and CPU-GPU codesign into the whole system, successfully addressing the previous issues. Overall Architecture of Milvus Query ProcessingSupport of query types: Vector Query (1 vector) Attribute Filtering (1 vector + n attribute constraints)(Advanced Query) Multi-vector Query (n vectors)(Advanced Query) Support of similarity functions: Euclidean distance Inner product Cosine similarity Hamming distance Jaccard distance Attribute Filtering A: ①obtain the satisfied vectors②fully scann them B: ①obtain the satisfied vectors②use bitmap to find the answer C: ①obtain more than k results②fully scan and find those satisfy the attribute constraint D: estimate the cost of A,B,C and find the best one E (Milvus): Partition-based filtering Create partitions for data Maintain min-max indexes for different partitions Skip the partitions whose range of attribute does not overlap with the queries’ Find the overlapping partitions, and apply strategy D(cost-based) within each partition Multi-vector Queries For decomposable similarity functions: Use aggregate functions to concentrate the vectors and find the k nearest neighbors based on the concentrated vector (vector fusion) For indecomposable similarity functions: Indexing (Querying) Quantization-based Indexing: (Quantization: represent vectors with a codebook. First find n nearest clusters to q, then use the indexing to search within these clusters.) IVF_FLAT IVF_SQ8 IVF_PQ Graph-based indexing: HNSW RNSG Vector and Attribute StorageTo facilitate query processing, Milvus stores vectors and attributes in a columnar fasion. Vectors: different vectors of entities are stored together correspondingly. Attributes: &lt;attr value, row ID&gt; pairs + skipping indexes (min-max) for pages Milvus also relies on LRU-based buffer and supports multiple file systems. Optimizations for Heterogeneous ComputingHow to find the top k similar vectors for multiple queries efficiently? CPU-oriented Optimization GPU-oriented Optimization CPU-GPU codesign CPU-oriented Optimization Faiss leveraged OpenMP to realize multi-threading. Each thread process a query at a time. Two issues: High cache-missing rate (requires to stream the entire data into caches, cannot reuse) Cannot fully exploit cores when query number is small Milvus assign threads to data vectors instead of query vectors to address the 2nd issue. Divide the queries into blocks s.t. each query block and its heaps can fit in L3 cache. Results are managed in heaps. To obtain the final results, merge the result. Milvus is also capable of automatically choosing SIMD instructions for functions. GPU-oriented Optimization Faiss: k&lt;=1024 because of the limit of memory Milvus: divide k into different rounds, each round expanding the obtained result set until reaches the required number.Faiss: must set the number of GPUs in advance; dynamic segment-based scheduling that assign search tasks to available devices CPU-GPU Co-design Limitations of Faiss (IVF_SQ8):Low PCIe bandwidth utilization (1 bucket per time)Data transfer makes GPU computing unbeneficial Milvus (SQ8H):High bandwidth utilization (Multiple buckets loaded per time)Assess the running mode (GPU-only or hybrid) based on the batch size Applications Recommender System Image Recognition Chemical Structure Analysis etc. EvaluationEvaluation (Comparing with other systems) 10M vectors from SIFT1B and Deep1B 10000 random queries Evaluation: cache-aware design Evaluation-Attribute Filtering","link":"/2024/02/02/Milvus/"},{"title":"How to build a PDF Autofiller Agent?","text":"How to build a PDF Autofiller Agent?Requirements:Design a Copilot Chatbox to provide such functionality: user uploads a PDF file with fields to fill in, and give Chatbox certain commands to fill out some fields. AI will use this command and identify the fields and values to fill, then fill those fields with the values that user specifies and return the form to users. Existing Tools Tool Printed Select Printed Edit Scanned Select Scanned Edit Comments Adobe Acrobat PDF ✅ ❓ ✅ ❓ Needs Pro subscription to edit ABBYY Finereader PDF Can’t install on Mac PDFfiller ✅ ✅ ❌ ❌ LuminPDF ✅ ❓ ✅ ❓ Need s Pro subscription to edit Workflow Overview123456789101112PDF form Template ↓PDF form parsing ↓PDF manifest Generation ↓LLM API ↓PDF filling engine ↓Generate filled PDF Tech Stack (Client-side, Serverless)PDF Form ParsingInput: PDF raw data 123456789101112 0 obj&lt;&lt; /Type /Annot /Subtype /Widget /FT /Tx % Field Type: Text /T (Age_Field) % Field Name (Key) /V ( ) % Value: Empty /Rect [100 100 200 120] % Position on page /AP &lt;&lt; /N 13 0 R &gt;&gt; % Appearance Stream (how it looks)&gt;&gt;endobj Since inputs and labels are not connected data structure-wise, i.e., they are not linked in the source code, unlike HTML where labels and inputs might be linked by id. The only way to identify related labels and inputs is to compare the coordinates. Web Browserpdf.js: parse raw PDF in browser. Output: return a map between each object (input or label) and its coordinates. 1234567891011{ id: annot.fieldName || &quot;unknown_id&quot;, // The internal ID (e.g., &quot;txt_01&quot;) type: annot.subtype, // &quot;Widget&quot; (usually) inputType: annot.fieldType, // &quot;Tx&quot; (Text), &quot;Btn&quot; (Button/Checkbox) rect: { x: Math.round(x), y: Math.round(y), width: Math.round(xMax - x), height: Math.round(yMax - y) }} PDF Manifest GenerationGiven the coordinates of each object, find the matching ones. Especially, for all the input fields, find the matching label. Return the relationship as a JSON. Using for-loops to calculate the Euclidean Distance between each coordinate pair can work. LLM Agentuse Vercel AI SDK to orchestrate the “Reasoning-Action” loop. The LLM does not modify the file directly; it acts as a router to decide which client-side tool to call. Framework: Next.js App Router + ai (Vercel AI SDK). Tool Calling: Define a tool schema (using Zod) that describes the form fields. The LLM outputs structured JSON matching this schema instead of plain text. Client-Side Execution: Use the useChat hook to intercept the LLM’s tool call. When the LLM requests fill_fields, the browser executes the JavaScript logic to update the PDF. PDF Filling Engine Library: pdf-lib (Client-side JavaScript). Logic: Load the PDF Uint8Array in memory. Locate fields using the IDs provided by the LLM tool call. Execute Write: form.getTextField(id).setText(value) form.getCheckBox(id).check() Update Appearance: Run form.updateFieldAppearances() to ensure text is rendered visibly (generating the /AP stream). Output: Generate a new Blob for user download. Tech Stack (Server-side)PDF Form ParsingInput: PDF raw data (Bytes) Similar to the JS version, inputs (Widgets) and visual labels (Text) are disconnected in the PDF structure. We need to extract them separately. Tool: PyMuPDF (import fitz) Why: Faster and more accurate coordinate extraction than other Python libraries. Output: A map between each object and its coordinates. Python 123456# Extracted using page.widgets() and page.get_text(&quot;words&quot;){ &quot;id&quot;: widget.field_name, # Internal ID (e.g., &quot;txt_01&quot;) &quot;type&quot;: widget.field_type, # Text, Checkbox, etc. &quot;rect&quot;: [x0, y0, x1, y1] # Bounding box coordinates} PDF Manifest GenerationLogic: Spatial Matching (Euclidean Distance). Given the coordinates of widgets and text blocks, find the matching pair. Algorithm: For each input field, calculate distance to all text blocks. Find the text that is closest (Top/Left priority) to the input field. Result: A clean JSON list linking field_id to label_text (e.g., {&quot;id&quot;: &quot;t1&quot;, &quot;label&quot;: &quot;Date of Birth&quot;}). LLM AgentTool: LangChain + Pydantic Use Pydantic to define the strict schema for the LLM output (Structured Output), replacing the need for raw prompt parsing. Workflow: Context Injection: Inject the PDF Manifest JSON directly into the System Prompt. Reasoning: LLM maps User Command -&gt; Field IDs. Output: LLM returns a Pydantic object (JSON) containing the fill plan. Python 123456class FieldUpdate(BaseModel): field_id: str value: str# LLM is forced to return this structurestructured_llm = chat_model.with_structured_output(FieldUpdate) PDF Filling EngineTool: pypdf Why: Robust support for writing AcroForms and updating appearance streams. Action: Load PDF bytes using PdfReader. Map the LLM’s Pydantic output to a dictionary: { &quot;field_id&quot;: &quot;value&quot; }. Execute filling: Python 12345writer.update_page_form_field_values( writer.pages[0], fields_dict, auto_regenerate=True # Crucial for visible text (/AP Stream)) Return the BytesIO stream to the user.","link":"/2026/01/15/PDF_Autofiller/"},{"title":"Common Data Structures and Methods in C++ STL","text":"Common Data Structures and Methods in C++ STL1. vector (Dynamic Array)1.1 Include1#include&lt;vector&gt; 1.2 Creation Create an empty vector 1vector&lt;int&gt; vct; Create a vector with a fixed length 1vector&lt;int&gt; vct(10); Create a vector with a fixed length and initialize all elements with a given value 1vector&lt;int&gt; vct(10, 1); Create a vector with specified elements 1vector&lt;int&gt; vct{1, 2, 3, 4, 5}; Create a vector using iterators 12vector&lt;int&gt; tmp{1, 2, 3, 4, 5};vector&lt;int&gt; vct(tmp.begin(), tmp.end()); 1.3 Methods Append elements at the end: push_back, emplace_back push_back() creates a temporary object first, then copies or moves it to the container.emplace_back() (introduced in C++11) constructs the object directly at the end. 12vct.push_back(1);vct.emplace_back(1); Insert elements at a specific position: insert, emplace Similarly, emplace is a new feature in C++11. 123vct.insert(pos, val); // insert val at posvct.insert(vct.begin()+2, 1); // insert 1 at index 2vct.insert(vct.begin()+2, 3, 1); // insert three 1s at index 2 Remove the last element: pop_back 1vct.pop_back(); Remove elements at a specific position: erase 12vct.erase(vct.begin()+2); // remove element at index 2vct.erase(vct.begin()+2, vct.begin()+5); // remove elements from index 2 to 4 Clear the vector 1vct.clear(); 2. stack2.1 Include1#include&lt;stack&gt; 2.2 Construct a stack object1stack&lt;int&gt; st; 2.3 Methods Push onto stack: push 12st.push(1);st.emplace(1); Pop from stack: pop 1st.pop(); // void function, only removes the top Get the top element: top 1int a = st.top(); Check if empty: empty 123if(!st.empty()){ ...} 3. queue3.1 Include1#include&lt;queue&gt; 3.2 Construct a queue object1queue&lt;int&gt; q; 3.3 Methods Enqueue: push, emplace 12q.push(1);q.emplace(1); Dequeue: pop 1q.pop(); Get front and back: front, back 12int a = q.front();a = q.back(); 4. deque (Double-ended Queue)4.1 Include1#include&lt;deque&gt; 4.2 Construct a deque object12deque&lt;int&gt; dq;deque&lt;int&gt; dq(len, val); 4.3 Methods Insert at front: push_front, emplace_front 12dq.push_front(1);dq.emplace_front(1); Insert at back: push_back, emplace_back 12dq.push_back(1);dq.emplace_back(1); Remove from front/back: pop_front, pop_back 12dq.pop_front();dq.pop_back(); Access front/back: front, back 12int a = dq.front();int b = dq.back(); Clear the deque 1dq.clear(); 5. set5.1 Include1#include&lt;set&gt; 5.2 Construct a set1set&lt;int&gt; s; 5.3 Methods Insert elements: insert, emplace 12s.insert(1);s.emplace(1); Remove elements: erase 1s.erase(1); // remove element with value 1 Find elements: count, find 123456if(s.count(1)){ // returns 1 if exists, otherwise 0 ...}if(s.find(1) != s.end()){ // returns iterator if exists, otherwise end() ...} Clear the set 1s.clear(); 6. map (Key-Value Mapping)6.1 Include1#include&lt;map&gt; 6.2 Construct1map&lt;char, int&gt; mp; 6.3 Methods Insert elements: insert, emplace 12mp.insert(pair&lt;char, int&gt;('a', 1));mp.emplace('a', 1); 中文原文 C++的STL库常用数据结构及方法1. vector可变数组1.1 引入1#include&lt;vector&gt; 1.2 创建 创建空vector 1vector&lt;int&gt; vct; 创建一定长度的vector 1vector&lt;int&gt; vct(10); 创建一定长度的vector，并且给所有元素赋初始值 1vector&lt;int&gt; vct(10, 1); 创建一个指定元素值的vector 1vector&lt;int&gt; vct{1, 2, 3, 4, 5}; 使用迭代器创建vector 12vector&lt;int&gt; tmp{1, 2, 3, 4, 5};vector&lt;int&gt; vct(tmp.begin(), tmp.end()); 1.3 方法 向尾部添加元素push_back, emplace_back push_back()会先创建一个临时对象，然后复制或移动到容器尾部。emplace_back是C++ 11新引入的方法，直接在容器尾部创建这个对象。 12vct.push_back(1);vct.emplace_back(1); 向某一位置插入元素insert，emplace 同理，emplace是C++ 11新特性 123vct.insert(pos, val);//在pos位置插入元素valvct.insert(vct.begin()+2, 1);//在下标为2处插入1vct.insert(vct.begin()+2, 3, 1);//在下标为2处插入3个1 删除尾部元素pop_back 1vct.pop_back(); 删除指定位置的元素erase 12vct.erase(vct.begin()+2);//删除下标为2的元素vct.erase(vct.begin()+2, vct.begin()+5);//删除下标为2到4的元素 清空vector 1vct.clear(); 2. stack栈2.1 引入1#include&lt;stack&gt; 2.2 构造stack对象1stack&lt;int&gt; st; 2.3 方法 入栈push 12st.push(1);st.emplace(1); 出栈pop 1st.pop();//void函数，仅出栈操作 获取栈顶top 1int a = st.top(); 判空empty 123if(!st.empty()){ ...} 3. 队列queue3.1 引入1#include&lt;queue&gt; 3.2 构造queue对象1queue&lt;int&gt; q; 3.3 方法 入队push，emplace 12q.push(1);q.emplace(1); 出队pop 1q.pop(); 获取队头、队尾元素front，back 12int a = q.front();a = q.back(); 4. 双向队列deque4.1 引入1#include&lt;deque&gt; 4.2 构造deque对象12deque&lt;int&gt; dq;deque&lt;int&gt; dq(len, val); 4.3 方法 前端插入元素push_front，emplace_front 12dq.push_front(1);dq.emplace_front(1); 后端插入元素push_back，emplace_back 12dq.push_back(1);dq.emplace_back(1); 前后端出队pop_front，pop_back 12dq.pop_front();dq.pop_back(); 访问元素front，back 12int a = dq.front();int b = dq.back(); 清空clear 1dq.clear(); 5. 集合set5.1 引入1#include&lt;set&gt; 5.2 构造set1set&lt;int&gt; s; 5.3 方法 插入元素insert，emplace 12s.insert(1);s.emplace(1); 删除元素erase 1s.erase(1);//删除值为1的元素 查找元素count，find 123456if(s.count(1)){//若存在则返回1，否则返回0 ...}if(s.find(1) != s.end()){//若存在则返回迭代器，否则返回end() ...} 清空clear 1s.clear(); 6. 键值映射map6.1 引入1#include&lt;map&gt; 6.2 构造1map&lt;char, int&gt; mp; 6.3 方法 插入元素insert, emplace 12mp.insert(pair&lt;char, int&gt;('a', 1));mp.emplace('a', 1);","link":"/2024/03/23/CppSTL/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; Detailed Explanation of Various Knapsack Problems (0&#x2F;1 Knapsack, Complete Knapsack, Multiple Knapsack)","text":"Dynamic Programming - Detailed Explanation of Various Knapsack ProblemsI remember really enjoying solving knapsack problems when I was learning algorithms, because mastering them gave a sense of enlightenment, as if I had learned secret martial arts techniques. This article records different scenarios and solutions for various knapsack problems. 1. 0/1 Knapsack ProblemThe 0/1 knapsack problem is as follows: Suppose there are n items, each item i has a volume vi and a value si, and there is a knapsack with capacity V. How to maximize the total value of items in the knapsack without exceeding its capacity? The idea is to consider adding items from few to many. First, number the items, then use a 2D dp array to store subproblem solutions. $dp[i][j]$ represents the maximum value that can be obtained with the first i items and knapsack capacity j. The final answer is $dp[n][V]$. $dp[i][j]$ may or may not include the i-th item. If not included, it’s $dp[i-1][j]$; if included, it’s $dp[i-1][j-v_i]+s_i$, which is the value of the i-th item plus the maximum value of the first i-1 items that fit in the remaining capacity after including item i. Hence the state transition equation is: $dp[i][j]=max(dp[i-1][j], dp[i-1][j-v_i]+s_i)$ How to dynamically update this 2D array? Both ways work: either by increasing capacity one by one or by adding items one by one. Here we add items one by one. 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;class Solution{public: int maxValue(vector&lt;int&gt;&amp; volume, vector&lt;int&gt;&amp; value, int V){ vector&lt;vector&lt;int&gt;&gt; dp; for (int i = 0; i &lt; volume.size() + 1; i++) { vector&lt;int&gt; row(V + 1, 0); dp.push_back(row); } for (int i = 0; i &lt; volume.size() + 1; i++){ for (int j = 0; j &lt; V + 1; j++){ if(i == 0 || j == 0){ dp[i][j] = 0; continue; } int newMax = 0; if(j &gt;= volume[i-1]){ newMax = dp[i - 1][j - volume[i-1]] + value[i-1]; } dp[i][j] = max(dp[i - 1][j], newMax); } } return dp[volume.size()][V]; }};int main(){ vector&lt;int&gt; volume{1, 2, 4, 8, 10}; vector&lt;int&gt; value{2, 3, 4, 5, 10}; int V = 20; Solution s; cout &lt;&lt; &quot;max value: &quot; &lt;&lt; s.maxValue(volume, value, V); return 0;} 2. Complete (Unbounded) KnapsackThe complete knapsack allows unlimited copies of each item. For $dp[i][j]$, it can be $dp[i][j-v_i]+s_i$, representing adding one more of the current item to the previous maximum for this item; or it can be $dp[i-1][j]$, representing not taking the current item and only taking the first i-1 items. So $dp[i][j]=max(dp[i][j-v_i]+s_i,dp[i-1][j])$ The code doesn’t need to be rewritten; just modify the previous state transition equation. Knapsack Optimization0/1 Knapsack OptimizationWhoever came up with this was really clever. Looking at the 2D array layer by layer, only the bottom row $dp[i-1][1,2,…,V]$ is actually needed to update the next row. So we can compress it to a 1D array, overwriting values like painting a wall repeatedly. We only need an array $dp[V]$, where in the i-th iteration, $dp[j]$ represents the maximum value for capacity j with the first i items. The state transition equation is: $dp[j]=max(dp[j],dp[j-v_i]+s_i)$ Here, $dp[j]$ inside max represents the previous iteration (i-1), i.e., the maximum value for capacity j considering the first i-1 items. There is a problem: if we update from $dp[1]$ to $dp[V]$, the term $dp[j-v_i]+s_i$ might use a value already updated in the current iteration, effectively including the i-th item twice, which violates the 0/1 knapsack definition. So we need to update in reverse order to ensure previous values are from the previous iteration. 12345678910111213int knapsack01Optimized(vector&lt;int&gt;&amp; volume, vector&lt;int&gt;&amp; value, int V){ vector&lt;int&gt; dp(V + 1, 0); for (int i = 0; i &lt; volume.size() + 1; i++){ for (int j = V; j &gt;= 0; j--){ if(j &gt;= volume[i - 1]){ dp[j] = max(dp[j], dp[j - volume[i - 1]] + value[i - 1]); } else{ dp[j] = dp[j]; } } } return dp[V];} This optimization does not change the time complexity, but reduces space complexity from $O(NV)$ to $O(V)$. Complete Knapsack Optimization0/1 knapsack must be updated in reverse, while multiple/complete knapsack needs forward updates to account for multiple copies of the current item. Looking at the state transition for complete knapsack: $dp[i][j]=max(dp[i][j-v_i]+s_i,dp[i-1][j])$ The presence of $dp[i][j-v_i]$ indicates using the current layer’s previous values, so we need to update front to back. Multiple Knapsack 中文原文 动态规划-各种背包问题详解记得当时学算法的时候可喜欢写背包问题了，因为学会了有种豁然开朗的感觉，仿佛掌握了武功秘籍。这篇文章就来记录一下各种背包问题的场景和解法。 1. 01背包问题01背包问题是这样的： 假如有一组n个物品，每个物品i都有一个体积vi和一个价值si，现在有一个容量有限为V的背包，如何在不超过该背包容量的情况下装走总价值最大的物品？ 这个问题的思想是通过从少到多地考虑装入的物品。首先将物品进行编号，然后使用一个二维的dp数组保存子问题的解。$dp[i][j]$表示考虑前i个物品，背包容量为j时所能装入的最大价值，那么问题的所求就是$dp[n][V]$ $dp[i][j]$可能包含第i个物品，也可能不包含。不包含时就是$dp[i-1][j]$，包含时就是$dp[i-1][j-v_i]+s_i$，也就是第i个物品的价值，加上去掉第i个物品占的空间后，装前i-1个物品最大能获得多少价值。因此有状态转移方程： $dp[i][j]=max(dp[i-1][j], dp[i-1][j-v_i]+s_i)$ 那么怎样动态地更新这个二维数组呢？答案是都行，即可以每次增加一个容量，也可以每次增加一个物品。这里按照每次增加一个物品来写。 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;class Solution{public: int maxValue(vector&lt;int&gt;&amp; volume, vector&lt;int&gt;&amp; value, int V){ vector&lt;vector&lt;int&gt;&gt; dp; for (int i = 0; i &lt; volume.size() + 1; i++) { vector&lt;int&gt; row(V + 1, 0); dp.push_back(row); } for (int i = 0; i &lt; volume.size() + 1; i++){ for (int j = 0; j &lt; V + 1; j++){ if(i == 0 || j == 0){ dp[i][j] = 0; continue; } int newMax = 0; if(j &gt;= volume[i-1]){ newMax = dp[i - 1][j - volume[i-1]] + value[i-1]; } dp[i][j] = max(dp[i - 1][j], newMax); } } return dp[volume.size()][V]; }};int main(){ vector&lt;int&gt; volume{1, 2, 4, 8, 10}; vector&lt;int&gt; value{2, 3, 4, 5, 10}; int V = 20; Solution s; cout &lt;&lt; &quot;max value: &quot; &lt;&lt; s.maxValue(volume, value, V); return 0;} 2. 完全背包完全背包就是每个物品有无限个。对于$dp[i][j]$，可以是$dp[i][j-v_i]+s_i$，表示少装一个当前物品的最大价值再加上当前物品的价值；也可以是$dp[i-1][j]$，表示不装当前物品，只装前i-1个物品时的最大价值。也就是 $dp[i][j]=max(dp[i][j-v_i]+s_i,dp[i-1][j])$ 代码就懒得重新写了，就把上一个的状态转移方程改一下就行。 背包问题优化01背包问题优化你说这玩意谁研究的呢，太聪明了。 我们看这个一层一层的二维数组，事实上每次只有最下面那行$dp[i-1][1,2,…,V]$才有用，再更新下一行的时候只需要用到之前的最下面那行，因此就可以压缩成一维的，像刷墙一样一遍一遍地覆盖。此时我们只需要一个数组$dp[V]$，在第i次循环中，$dp[j]$就表示考虑前i个物品时，容量为j的背包最大价值。那么状态转移方程就是： $dp[j]=max(dp[j],dp[j-v_i]+s_i)$ 这里max里面的$dp[j]$就是上一轮（i-1轮）的，表示考虑前i-1个物品时容量为j的最大价值。那么这里就有一个问题。按照原来的顺序更新，应该从$dp[1]$更新到$dp[V]$，但是更新到后面，$dp[j-v_i]+s_i$又需要用前面的值，但是前面的值又已经被覆盖了，可能就已经包含了第i个物品，这里如果再拿一个，不符合01背包的定义了。因此这里我们需要倒序更新，这样保证前面的值还是上一轮的。 12345678910111213int knapsack01Optimized(vector&lt;int&gt;&amp; volume, vector&lt;int&gt;&amp; value, int V){ vector&lt;int&gt; dp(V + 1, 0); for (int i = 0; i &lt; volume.size() + 1; i++){ for (int j = V; j &gt;= 0; j--){ if(j &gt;= volume[i - 1]){ dp[j] = max(dp[j], dp[j - volume[i - 1]] + value[i - 1]); } else{ dp[j] = dp[j]; } } } return dp[V];} 这样的时间复杂度其实没变，空间复杂度从$O(NV)$降低为$O(V)$ 完全背包问题优化01背包问题要从后往前更新，而多重背包问题恰好相反，因为人家就是要考虑算了多个当前物品的情况。区别在哪呢，我们观察完全背包问题的状态转移方程 $ dp[i][j]=max(dp[i][j-v_i]+s_i,dp[i-1][j]) $ 可以发现这里出现是$dp[i][j-v_i]$，也就是当前这一层的前面的值，这也就说明我们需要先更新前面再更新后面。 多重背包","link":"/2024/06/15/Knapsack%20Problems/"},{"title":"Python Fundamentals - 1. Variables and Copy","text":"[Python Foundamentals]1. Variables and CopyVariable Typesimmutable variableimmutable variables include : int string tuple When a function is called, the immutable variable parameters are passed by value. For immutable variables, shallow copy and deep copy both will not allocate new memory space for the new variable. The two kinds of copies only build a reference relationship between the old object and the new object. mutable variableimmutable variables include: set list dict When a function is called, the mutable variable parameters are passed by reference. For mutable variables, shallow copy and deep copy both will allocate new memory space for the new variable. However, for the immutable variables contained in mutable variables like lists, they are still shallow copied. So the deep copy of mutable variables just copy themselves, excluding the immutable variables contained. two kinds of ‘copy’Shallow copy is quite unanimous for all kinds of variables. However, deep copy for complex variables that have multi layers is worth discussing. Actually, the principle can be concluded as: For each layer, follow the following rules recursively: If the current layer is immutable, and all sub-elements are immutable, then no new space and object will be allocated for this layer. If the current layer is immutable, and some of the sub-elements are mutable, then deep-copy these sub-elements and the current layer. If the current layer is mutable, create a new object for the current layer, and copy the sub-elements depending on their mutability recursively. That’s based on my comprehension, some might be wrong. Referenceshttps://zhuanlan.zhihu.com/p/487677774 https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&amp;mid=2247569389&amp;idx=4&amp;sn=7f93a257c597821bb55da3e2637a3f3d&amp;chksm=fb542d01cc23a4178b83617a01e933494ca6274dd2086baf2bd0354ac30637cc9af674458116&amp;scene=27 https://blog.csdn.net/m0_59044674/article/details/127267173 https://towardsdatascience.com/an-overview-of-mutability-in-python-objects-8efce55fd08f","link":"/2023/02/25/%5BPython%20Interview%5D1.%20Variables%20and%20Copy/"},{"title":"Learn more about me and the cool products I have contributed to!","text":"I am Zhaorui Ding, currently pursuing MSCS at Georgia Institute of Technology (Atlanta Campus). I am expected to graduate in Dec 2026 - May 2027. Education Background 2027: Master of Science in Computer Science, Georgia Institute of Technology 2024: Bachelor of Engineering in Computer Science and Technology, Huazhong University of Science and Technology GPA: 3.83/4.00 2020: Tsinghua University High School Professional Experience Jun 2025 - Aug 2025: Software Engineer Intern, Tencent, WXG (WeChat Group). Developed back end and LLM platform for WeChat. Feb 2025 - Jun 2025: Software Engineer Intern, SLB. Developed back end for Drillplan Web App Sep 2024 - Feb 2025: Software Engineer Intern, Microsoft. Developed backend for Bing Image feed. Cool products that I contributed to during internships WeChat Public Account Translation Bing Image Feed Bing Image Feed Research Experience Research Assistant 03/2023 - 09/2023 Intelligent Data Storage and Management Laboratory, Wuhan National Laboratory for Optoelectronics Supervisor: Hua Wang Research Assistant 03/2023 - 09/2023 Department of AI for Biology, Shanghai Artificial Intelligence Laboratory","link":"/2025/09/10/aboutme/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 110.Container With Most Water","text":"LeetCode 110. Container With Most WaterProblem Link How to approach this? Consider two vertical lines. If the left line is taller than the right line, then if we choose either of these as the left boundary, the right one will always be limiting. Look at the two endpoints of the array. If the left line is shorter, it doesn’t matter how tall the right line is; this is the “bottleneck effect.” Therefore, any container using the leftmost line as the left boundary cannot be the largest. In other words, the leftmost line can be “skipped.” Next, calculate the container’s area, then move the left pointer rightward to the next line. For the new endpoints, apply the same logic: discard the shorter line. Repeat this process until the two pointers meet. 1234567891011121314151617class Solution {public: int maxArea(vector&lt;int&gt;&amp; height) { int left = 0, right = height.size() - 1; int maxVolume = 0; while(left &lt; right){ int curVolume = (right - left) * min(height[left], height[right]); maxVolume = max(maxVolume, curVolume); if(height[left] &gt;= height[right]){ right--; } else{ left++; } } return maxVolume; }}; 中文原文 LeetCode 110. 盛水最多的容器题目链接 怎样思考这个问题？首先我们从左往右看一看，假如有两根柱子，左边的柱子比右边的高，那么当选取这两个柱子之一作为左边的容器壁时，右边的柱子是一定会输的。 考虑数组的左右两个端点，假如左边的柱子更矮，那么右边的柱子无论再怎么高也没有用，这就是所谓的木桶效应。所以事实上以最左侧柱子为左端点的容器都不需要看了，因为不会有比现在更大的了。这也就是说，最左侧的柱子被“pass”了。 那么接下来就算一下这个容器的容量，然后把最左侧的柱子扔了，换第二个，也就是left指针右移。对于新的左右端点，运用同样的思路，排掉较短的那一根，如此循环直到左右端点相遇。 1234567891011121314151617class Solution {public: int maxArea(vector&lt;int&gt;&amp; height) { int left = 0, right = height.size() - 1; int maxVolume = 0; while(left &lt; right){ int curVolume = (right - left) * min(height[left], height[right]); maxVolume = max(maxVolume, curVolume); if(height[left] &gt;= height[right]){ right--; } else{ left++; } } return maxVolume; }};","link":"/2024/07/24/lc_110_%E7%9B%9B%E6%B0%B4%E6%9C%80%E5%A4%9A%E7%9A%84%E5%AE%B9%E5%99%A8/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 128. Convert Sorted Array to Binary Search Tree","text":"LeetCode 128. Convert Sorted Array to Binary Search TreeProblem Link This problem is quite interesting. At first glance, it seems simple, but a closer look reveals some subtle traps. The expanded result is in preorder traversal order. That is, for any node, after expansion, its right subtree sequence should follow root → left subtree → right subtree, and the left and right subtrees themselves are also expanded in the same way. So for a node, we first need to link the left subtree to the right subtree, then perform the same operation for both subtrees. This process is called Morris traversal. The method is to find the rightmost node of the left subtree and attach the right subtree to it. The correctness of this approach can be visualized by drawing a line with slope -1, essentially peeling layer by layer along this direction. A good illustration can be found on Zhihu. After connecting the left subtree to the right, we need to perform the same operation inside the left subtree. At this point, the left subtree is actually the current node’s right child, so we move the pointer to the right child and repeat the loop. Similarly, the right subtree is handled automatically as the pointer keeps moving right and eventually reaches the original right child. The implementation is as follows: 1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: void flatten(TreeNode* root) { TreeNode* cur = root; while(cur){ TreeNode* leftRight = cur-&gt;left; if(leftRight){ while(leftRight-&gt;right){ leftRight = leftRight-&gt;right; } leftRight-&gt;right = cur-&gt;right; cur-&gt;right = cur-&gt;left; cur-&gt;left = nullptr; } cur = cur-&gt;right; } }}; 中文原文 LeetCode 128. 将有序数组转化为二叉搜索树题目链接 这个题有点意思，乍一看挺简单，想一下就会发现有点点坑。 展开的结果是先序遍历的顺序，也就是说对于某个节点，展开后它的右子树这一串应该是根节点→左子树→右子树这个顺序，而左子树和右子树也是这样展开的。 所以对一个节点，我们首先要将左子树链到右子树中，再对左右子树都执行这个操作。这个过程的实现方法叫做Morris遍历，方法是找到左子树的最右节点，再将右子树接到该节点的下面。可以画一条$y=-x$的斜线，这个过程就相当于沿着这个方向一层一层剥开。知乎上找到一个挺好的示意图 每次把左子树连到右子树之后，需要再对左子树内也进行同样的操作，但是此时左子树就是我们根节点的右孩子，因此把指针移动到右孩子，重复这个循环。此外，右子树也需要执行这个操作，同样不用担心，指针一直往右移动，早晚会指向原本的右子树的根节点，也就是原来的右孩子。代码实现如下： 1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: void flatten(TreeNode* root) { TreeNode* cur = root; while(cur){ TreeNode* leftRight = cur-&gt;left; if(leftRight){ while(leftRight-&gt;right){ leftRight = leftRight-&gt;right; } leftRight-&gt;right = cur-&gt;right; cur-&gt;right = cur-&gt;left; cur-&gt;left = nullptr; } cur = cur-&gt;right; } }};","link":"/2024/07/28/lc_114_%E4%BA%8C%E5%8F%89%E6%A0%91%E5%B1%95%E5%BC%80%E4%B8%BA%E9%93%BE%E8%A1%A8/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 105. Construct Binary Tree from Preorder and Inorder Traversal","text":"LeetCode 105. Construct Binary Tree from Preorder and Inorder TraversalProblem Link The key to this problem is understanding that: Preorder traversal sequence is: [root, left subtree, right subtree] Inorder traversal sequence is: [left subtree, root, right subtree] Given a preorder sequence, the first element is always the root. Once we know the root, and since all values are unique, we can find the root’s position in the inorder sequence. This allows us to determine the ranges of the left and right subtrees in the inorder sequence and calculate their lengths, which in turn gives the ranges for the preorder left and right subtrees. This way, the left and right child nodes can be determined. Recursively, we can do the same for each subtree by narrowing the ranges. The recursion parameters are simply the start and end indices for the preorder and inorder sequences to define the current subtree range. Additionally, a hash map can store the index of each value in the inorder sequence for O(1) lookup, avoiding repeated O(n) searches. 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: unordered_map&lt;int, int&gt; inorderMap; TreeNode* recur(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder, int preStart, int preEnd, int inStart, int inEnd){ if(preEnd &lt; preStart) return nullptr; int rootVal = preorder[preStart]; int inRootPos = inorderMap[rootVal]; int leftSize = inRootPos - inStart; TreeNode* left = recur(preorder, inorder, preStart + 1, preStart + leftSize, inStart, inRootPos - 1); TreeNode* right = recur(preorder, inorder, preStart + leftSize + 1, preEnd, inRootPos + 1, inEnd); TreeNode* root = new TreeNode(rootVal, left, right); return root; } TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) { for(int i = 0; i &lt; inorder.size(); i++){ inorderMap[inorder[i]] = i; } return recur(preorder, inorder, 0, inorder.size() - 1, 0, inorder.size() - 1); }}; 中文原文 [LeetCode hot 100] 105. 从前序与中序遍历序列构造二叉树题目链接 这个题的关键是理解前序遍历的序列是：【根节点，【左子树】，【右子树】】，而中序遍历的序列是【【左子树】，根节点，【右子树】】。当我们拿到一个前序遍历的序列，唯一能确定的就是第一个数一定是根节点。拿到根节点后，由于没有重复值，所以可以确定中序遍历序列中根节点的位置，从而得到中序遍历的左子树区间和右子树区间，并且得到这两个区间的长度，这样前序遍历的左子树区间和右子树区间也可以确定了。进而，左孩子节点和右孩子节点就可以确定了。 如果我们只看前序和中序的左子树的区间，就可以再得到左子树的左右孩子，以此类推，所以这是一个递归的过程，递归的参数只需要加上两个序列的起止点，来圈定当前子树的区间。 特别地，可以使用哈希表来存放每个值在中序遍历序列中的位置，这样就不用每次都用O(n)或O(logn)的时间查一遍了。 完整代码如下 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: unordered_map&lt;int, int&gt; inorderMap; TreeNode* recur(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder, int preStart, int preEnd, int inStart, int inEnd){ if(preEnd &lt; preStart) return nullptr; int rootVal = preorder[preStart]; int inRootPos = inorderMap[rootVal]; int leftSize = inRootPos - inStart; TreeNode* left = recur(preorder, inorder, preStart + 1, preStart + leftSize, inStart, inRootPos - 1); TreeNode* right = recur(preorder, inorder, preStart + leftSize + 1, preEnd, inRootPos + 1, inEnd); TreeNode* root = new TreeNode(rootVal, left, right); return root; } TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) { for(int i = 0; i &lt; inorder.size(); i++){ inorderMap[inorder[i]] = i; } return recur(preorder, inorder, 0, inorder.size() - 1, 0, inorder.size() - 1); }};","link":"/2024/07/28/lc_105_%E4%BB%8E%E5%89%8D%E5%BA%8F%E4%B8%8E%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"title":"注意力机制和Transformer模型（未完）","text":"注意力机制和Transformer模型前言在Attention出现前，RNN、LSTM这种Encoder-Decoder模型是序列处理的主流模型。这种架构把任务分为两个部分，第一是Encoder：将输入通过某种方式编码为一个固定长度的向量，称为Context Vector；第二步是Decoder：将Context Vector解码，逐字生成目标输出序列。RNN和LSTM主要是将每一轮的输出作为下一轮的输入，循环地生成输出直到结尾。但是这样首先是一个串行的步骤，性能不佳，而且如果输入太长，由于Context Vector的长度有限，难以捕捉全部的输入信息， Attention机制的引入2014年，为了解决context vector的这个问题，蒙特利尔大学的Dzmitry Bahdanau首次在NLP领域应用了Attention机制。这种初级的Attention机制被称为Bahadnau Attention。Bahdanau Attention认为Context Vector不应该是静态的。原本的RNN使用隐藏状态来保存记忆。Encoder计算隐藏状态的方法是： $$ h_t=\\tanh (W_{encode}\\cdot h_{t-1} + U_{encode}\\cdot x_t + b) $$ 可以简写为： $$h_t = \\text{RNN}(h_{t-1}, x_t)$$ 其中$ h_t$就是t时刻的隐藏状态，$x_t$就是t时刻的输入。通过分别和W、U相乘，决定了我们保留多少过去的记忆和新的信息。同样地，Decoder也有隐藏状态： $$s_t = \\tanh(W_{dec} \\cdot s_{t-1} + U_{dec} \\cdot [y_{t-1}, c_t] + b_{dec})$$ 可以简写为 $$s_t = \\text{RNN}(s_{t-1}, y_{t-1},c_t)$$ 这里的$c_t$就是Context Vector。在普通RNN中，这个就是最后一轮Encoder的$h_t$。但是如果序列层过长，由于隐藏层记忆了太多轮，会导致记忆的丢失。 Bahdanau Attention解决这个问题的方法是：首先，不再只存一个$h$，而是对于整个Encode过程中的所有$h$，全部保留下来，存在一个矩阵里。然后在Decoder前面增加了一个小型的神经网络，输出每个token时，都计算一下当前已经输出的序列和每个h之间的分数： $$score(s_{t-1}, h_j) = v^T \\tanh(W s_{t-1} + U h_j)$$ 这里的$s_t$是Decoder的隐藏状态。 使用Softmax把这些分数做一个归一化： $$a_{tj} = \\frac{\\exp(score_i)}{\\sum \\exp(score_k)}$$ 就计算出对每个h的注意力权重。然后根据这个注意力权重来算出Context Vector: $$ c_t=\\sum_{j}a_{tj}h_j $$ 也就是对所有$h$进行一个加权求和。使用这个context vector给Decoder，Decoder再生成输出并计算$s_t$ 由于这里的score分数是采用了s和h相加而成，因此Bahdanau Attention也被称为加性注意力（Additive Attention）。 Attention机制的改良2015年，斯坦福大学的Minh-Thang Luong对Attention机制进行了改良，与其还要单独用一个神经网络计算注意力，不如直接用点积来计算相似度： $$score(s_{t-1},h_j)=s_{t-1}^T\\cdot h_j$$ 这样直接做矩阵乘法，充分利用了GPU的性能。 Attention再进化——Self Attention2017年，Google发布了著名论文Attention is All You Need，直接把传统RNN结构取代，改为只用Attention。之前的结构里，RNN在Encode时每次计算一个h，然后Decode时每次和h算一个注意力分数。 Attention is All You Need中指出，我们不需要再做这种麻烦的注意力计算方式，而是采用“Self Attention“，对于输入序列中的每个词，我们直接计算其与序列中其他词的","link":"/2025/01/20/attention_transformer/"},{"title":"Covariate Shift, Label Shift and Concept Shift","text":"[Dive into Deep Learning] Covariate Shift, Label Shift and Concept ShiftWhen studying distribution shift, these concepts kept confusing me for a long time. After searching they finally become clearer. Covariate ShiftFirst, what exactly is a covariate in machine learning? Well, after searching I found that covariates in statistics corresponds with features in machine learning, which means that covariate shift is actually the shift of features. In many cases, the features of test datasets might differ from those of the training data sets, yet the labels remain the same. For example, one model is trained with a set of real dog pictures, but it might be required to distinguish a comic dog like Snoopy. The model has never seen Snoopy-like cartoon dogs before, and such dogs have different distribution of features and labels with real dogs, but they share the same label: dog. Such a shift of distribution is called covariate shift. Label ShiftLabel shift is exactly the opposite of covariate shift. Here is what I found at https://towardsdatascience.com, written(or quoted) by Dr. Matthew Stewart: Prior probability shift appears only in Y-&gt;X problems, and is defined as the case where Ptra(x|y) = Ptst(x|y) and Ptra(y) ≠ Ptst(y). So therefore the example of diseases and symptoms makes sense. We want to predict disease by symptoms, so ‘symptoms’ is X, and ‘diseases’ is Y. Apparently diseases cause symptoms, so this is a typical Y-&gt;X case. The distribution of diseases is not always the same, since diseases occur at different rates in different seasons, so the distribution of Y changes. This is a label shift. Concept ShiftConcept shift is different, it is the mere change of P(y|x). Let’s assume there was once a type of medicine, but it was later redefined as a type of beverage by FDA, though its ingredients remains the same. So a model developed at the earlier period trying to classify medicine and beverage by the ingredients may not work well later. That is my preliminary understanding of distribution shifts in this book. There’s still some ambiguity though, and I’ll keep working on that. ​","link":"/2023/01/29/%5BDive%20into%20Deep%20Learning%5D%20Covariate%20Shift,%20Label%20Shift%20and%20Concept%20Shift/"},{"title":"SpotServe, Serving Generative Large Language Models on Preemptible Instances","text":"SpotServe: Serving Generative Large Language Models on Preemptible InstancesAuthor: Xupeng Miao, et al. BackgroundGenerative LLM Input: tokens; Output: token sequence Stops when: output reaches maximum length/ending token Two types of GPU Instances On-demand GPUs: Expensive Use anytime you need Preemptible GPU Instances (e.g. Spot Instances): Cheap (run on spare capacity) Might be Preempted anytime Offers a grace period after preemption to complete currently running tasks Challenges The number of available preemptible instances changes frequently =&gt; Dynamic reparallelization for optimized serving performance Restarting LLM results in great overhead of reloading parameters =&gt; Find the optimal migration strategy that minimize the cost Grace periods may not be long enough for finishing current request The reduction of throughput during this process might lead to accumulation of subsequent requests SpotServeOverview Request Manager: handle requests, partition into batches, assign them to instances, send output to users Instance server: monitor the preemption and acquisition of instances Meta-context manager: schedule the context migration between GPU instances (parameters, outputs, etc.) Meta-context ManagerParallelization ControllerParallelization Configurations: D: Data Parallelization: partition requests and assign them to different pipelines P: Pipeline model parallelization: run different stages of a inference process simultaneously (like pipeline in CPU) M: Tensor model parallelization: split the model into shards and assign to different GPUsParallel Configuration C = (D, P, M) Configuration Optimizer If there is a configuration such that the throughput is larger than the request arrival rate, then choose the configuration that has minimum inference latency while making sure the throughput is larger than arrival rate. Otherwise, find the C for maximum throughput. After adjusting the configuration, allocate or free instances. Offline process =&gt; low latency What do we have now? We now have a configuration for the next step. However, we only decided the parallelization structure. How should us decide how to map the physical instances to logical positions? Device Mapper Goal: find the matching strategy that maximize reusable context (i.e., edge weight sum) Approach: *KM (*Kuhn-Munkres) Algorithm for Bipartite Graph Maximum Weight Matching edges: e(u, v) indicates reusable parameters and caches when mapping GPU u to position v. Migration Planner From front layers (0, 1) to back layers (N), find the layers whose context do not exceed the buffer size and prioritize migration of these layers. For other layers, add them to the sequence by the order of instance buffer memory usage After we have the sequence, sequentially migrate the layers in this sequence. If all layers of a specific stage is migrated, start running this stage. Just-in-time ArrangementWhat should we do if we receive a preemption/acquisition notification while there are still requests running/waiting? Immediately suspend and migrate? =&gt; high inference latency Finish all requests? =&gt; no enough time for migration SpotServe: for preemption, maximize token generation (since migration happens during the grace period); for acquisition, minimize token generation when exploiting the whole grace period (since migration happens after the grace period) Experimental EvaluationComparison Stable workload P99: latency at the 99th percentage (99% latency &lt;= this value) Baselines: FasterTransformer (reparallelization but no cocntext migration, rerouting with pre-defined config) Fluctuating Workload Ablation","link":"/2024/02/02/SpotServe/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 128. Convert Sorted Array to Binary Search Tree","text":"LeetCode 128. Convert Sorted Array to Binary Search TreeProblem Link It’s natural to think of using recursion for this problem, which is also the standard approach to construct a binary search tree. Each time, we take the middle element of the current range as the root node and recursively find the left and right children in the left and right halves (i.e., the midpoints of the halves). The only thing to note is: what are we doing in each recursion? Answer: we find the current node and recursively construct its left and right children. As long as both children don’t exist, we could return, but it’s simpler to just go one layer deeper. If the current node doesn’t exist (i.e., left &gt; right), it means we’ve reached a non-existent child, so we return null, which conveniently allows the parent to set the corresponding child pointer to null. The complete code is as follows: 12345678910111213141516171819202122232425262728/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: TreeNode* recur(vector&lt;int&gt;&amp; nums, int left, int right){ if(left &gt; right) return nullptr; int mid = left + (right - left) / 2; TreeNode* cur = new TreeNode(nums[mid]); cur-&gt;left = recur(nums, left, mid - 1); cur-&gt;right = recur(nums, mid + 1, right); return cur; } TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) { int left = 0; int right = nums.size() - 1; return recur(nums, left, right); }}; 中文原文 LeetCode 128. 将有序数组转化为二叉搜索树题目链接 这个题很自然地想到要用递归，这也是构建二叉搜索树的标准步骤。每次都从当前的区间取中点作为根节点，并且分别在左右半区内寻找左孩子和右孩子（即左右半区的中点），如此递归。唯一需要注意的是我们在每次递归中都在做些什么？答：我们找到当前的节点，并调用递归来构造当前节点的左右孩子节点。只要左右孩子都没有就可以返回了，但是这样判断起来太麻烦，不如直接再往深了走一层，假如当前节点不存在(即left &gt; right)，就说明走到了不存在的孩子那一层，返回null即可，正好方便父节点把对应孩子的指针设为null。 完整代码如下 12345678910111213141516171819202122232425262728/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: TreeNode* recur(vector&lt;int&gt;&amp; nums, int left, int right){ if(left &gt; right) return nullptr; int mid = left + (right - left) / 2; TreeNode* cur = new TreeNode(nums[mid]); cur-&gt;left = recur(nums, left, mid - 1); cur-&gt;right = recur(nums, mid + 1, right); return cur; } TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) { int left = 0; int right = nums.size() - 1; return recur(nums, left, right); }};","link":"/2024/07/28/lc_128_%E5%B0%86%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E8%BD%AC%E5%8C%96%E4%B8%BA%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; leetcode hot100. 22.Generate Parenthesis","text":"[LeetCode hot 100] 22. Generate ParenthesisThis is also a backtracking problem. The key is to realize that in an existing sequence, the number of left parentheses can never be less than the number of right parentheses; otherwise, there will be unmatched right parentheses. When the sequence is empty, the first character must be a left parenthesis &quot;(&quot;. Once there is one &quot;(&quot;, the second character can be either &quot;(&quot; or &quot;)&quot;. If the second character is &quot;(&quot;, the third character can be anything, but if the second character is &quot;)&quot;, the previous left and right parentheses are all matched, so the third character must be a left parenthesis. With this idea, during the downward search: If the total number of left parentheses so far is greater than the total number of right parentheses, the next character can be either &quot;(&quot; or &quot;)&quot;. If the total number of left parentheses equals the total number of right parentheses, the next character must be &quot;(&quot;. 12345678910111213141516171819202122232425262728class Solution {public: vector&lt;string&gt; generateParenthesis(int n) { vector&lt;string&gt; ans; string cur; backtrack(ans, cur, n, n); return ans; } void backtrack(vector&lt;string&gt;&amp; ans, string cur, int left, int right){ if(left == 0){ while(right &gt; 0){ cur += &quot;)&quot;; right--; } ans.push_back(cur); return; } if(left &lt; right){ backtrack(ans, cur+&quot;(&quot;, left-1, right); backtrack(ans, cur+&quot;)&quot;, left, right-1); } else{ backtrack(ans, cur+&quot;(&quot;, left-1, right); } }}; 中文原文 [LeetCode hot 100] 22. 括号生成Generate Parenthesis这个也是一道回溯题，核心是要意识到一个现有的序列中左括号数量一定不能比右括号少，否则就会出现有右括号没有左括号对应的情况。什么都没有的情况下，第一个只能来左括号，当有一个”(“，第二个就可以是”(“或”)”。如果第二个是”(“，第三个是啥都行，但是如果第二个是”)”，前面的左括号和右括号就全部配对了，第三个就只能是左括号。有了这个思路，每次向下搜索时： 如果之前序列左括号总数大于右括号总数，下一个就可以是左括号也可以是右括号。 如果左括号总数等于右括号总数，下一个就只能是左括号。 那么就可以写代码了： 12345678910111213141516171819202122232425262728class Solution {public: vector&lt;string&gt; generateParenthesis(int n) { vector&lt;string&gt; ans; string cur; backtrack(ans, cur, n, n); return ans; } void backtrack(vector&lt;string&gt;&amp; ans, string cur, int left, int right){ if(left == 0){ while(right &gt; 0){ cur += &quot;)&quot;; right--; } ans.push_back(cur); return; } if(left &lt; right){ backtrack(ans, cur+&quot;(&quot;, left-1, right); backtrack(ans, cur+&quot;)&quot;, left, right-1); } else{ backtrack(ans, cur+&quot;(&quot;, left-1, right); } }};","link":"/2024/06/15/lc_22_generate_parenthesis/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; leetcode hot100 - 23. Merge k Sorted Lists","text":"[LeetCode Hot 100] 23. Merge k Sorted ListsProblem Link Merging two linked lists is straightforward: use two pointers pointing to the two lists and move the pointer with the smaller value each time. However, here we have k lists. If we use k pointers and move the smallest one each time, we would need to traverse all k pointers to find the minimum each time, which is too inefficient. Finding the minimum among k elements is a perfect scenario for using a heap. About heap knowledge, see here. We use a min-heap here because we want the smallest element each time. The heap top is a pointer to a current node in one of the lists. After taking the heap top, we move that pointer to the next node and put it back into the heap. This is conveniently done by replacing the heap top and adjusting down. Below is the complete code. I took a shortcut by using sorting to build the heap. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */class Solution {public: void adjustDown(vector&lt;ListNode*&gt;&amp; heap){ int parent = 0; while(2 * parent + 1 &lt; heap.size()){ int lchild = 2 * parent + 1; int minChild = lchild; if(lchild + 1 &lt; heap.size()){ int rchild = lchild + 1; minChild = heap[lchild]-&gt;val &lt; heap[rchild]-&gt;val ? lchild : rchild; } if(heap[parent]-&gt;val &lt; heap[minChild]-&gt;val){ return; } swap(heap[parent], heap[minChild]); parent = minChild; } return; } void headPop(vector&lt;ListNode*&gt;&amp; heap){ swap(heap[0], heap[heap.size() - 1]); heap.pop_back(); adjustDown(heap); } ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) { vector&lt;ListNode*&gt; heap; for(auto&amp; head : lists){ if(head) heap.push_back(head); } // Use sorting to simulate heap construction sort(heap.begin(), heap.end(), [](ListNode* a, ListNode* b){return a-&gt;val &lt; b-&gt;val;}); ListNode dummy(0); ListNode* cur = &amp;dummy; while(heap.size() &gt; 0){ cur-&gt;next = new ListNode(heap[0]-&gt;val); cur = cur-&gt;next; if(heap[0]-&gt;next == nullptr){ headPop(heap); } else { heap[0] = heap[0]-&gt;next; adjustDown(heap); } cout&lt;&lt;heap.size()&lt;&lt;endl; } return dummy.next; }}; 中文原文 [LeetCode hot 100] 23. 合并k个升序链表题目链接 如果是合并两个链表那没得说，两个指针分别指向两个链表，每次把小的那个后移。 但是这里是k个，如果用k个指针，每次移动最小的，那么每次都需要遍历一遍找到最小的那个，时间复杂度太高了。 从k个里面找最小，这个情景很适合使用【堆】这种结构。关于堆的知识点传送门 这里使用小根堆，因为每次要获得最小的，那么小根堆取堆顶就能很轻松地完成这个工作。堆顶是一个指针，指向某个链表的遍历位置，当取了堆顶之后，需要将遍历指针向后移动一位，并且重新加入到堆中，这里就是把堆顶替换掉，然后向下调整，最为方便。 下面是完整代码，其中我偷了点懒，建堆就直接用排序代替了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */class Solution {public: void adjustDown(vector&lt;ListNode*&gt;&amp; heap){ int parent = 0; while(2 * parent + 1 &lt; heap.size()){ int lchild = 2 * parent + 1; int minChild = lchild; if(lchild + 1 &lt; heap.size()){ int rchild = lchild + 1; minChild = heap[lchild]-&gt;val &lt; heap[rchild]-&gt;val ? lchild : rchild; } if(heap[parent]-&gt;val &lt; heap[minChild]-&gt;val){ return; } swap(heap[parent], heap[minChild]); parent = minChild; } return; } void headPop(vector&lt;ListNode*&gt;&amp; heap){ swap(heap[0], heap[heap.size() - 1]); heap.pop_back(); adjustDown(heap); } ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) { vector&lt;ListNode*&gt; heap; for(auto&amp; head : lists){ if(head) heap.push_back(head); } //这里用排序实现了建堆，效果是一样的 sort(heap.begin(), heap.end(), [](ListNode* a, ListNode* b){return a-&gt;val &lt; b-&gt;val;}); ListNode dummy(0); ListNode* cur = &amp;dummy; while(heap.size() &gt; 0){ cur-&gt;next = new ListNode(heap[0]-&gt;val); cur = cur-&gt;next; if(heap[0]-&gt;next == nullptr){ headPop(heap); } else { heap[0] = heap[0]-&gt;next; adjustDown(heap); } cout&lt;&lt;heap.size()&lt;&lt;endl; } return dummy.next; }}; 自己独立写出来了，有点子感动。","link":"/2024/08/20/lc_23_%E5%90%88%E5%B9%B6k%E4%B8%AA%E5%8D%87%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 141(142). Linked List Cycle","text":"LeetCode 141(142). Linked List CycleProblem Link To detect a cycle in a linked list with O(1) space complexity, the Floyd’s Tortoise and Hare algorithm is used. A detailed explanation of Floyd’s algorithm can be found here. Steps: Initialize a fast pointer (fast) and a slow pointer (slow) at the head of the linked list. Move fast two steps at a time, and slow one step at a time. If fast reaches null, there is no cycle. If fast and slow meet, a cycle exists. Then proceed to step 4. Move one pointer back to the head of the list while keeping the other at the meeting point. Move both pointers one step at a time until they meet again. The meeting point is the entrance of the cycle. Complete code: 12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode *detectCycle(ListNode *head) { ListNode* fast = head; ListNode* slow = head; while(fast &amp;&amp; fast-&gt;next &amp;&amp; fast-&gt;next-&gt;next){ fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; if(slow == fast){ fast = head; while(fast != slow){ fast = fast-&gt;next; slow = slow-&gt;next; } return fast; } } return nullptr; }}; 中文原文 LeetCode 141(142). 环形链表题目链接 环形链表的判断在要求空间复杂度为O(1)时，需要使用Floyd判圈法来判断是否存在环。Floyd判圈法的具体讲解看这里。 具体步骤为： 快指针fast和慢指针slow指向链表头（首元结点） fast每次移动两步，slow每次移动一步 如果遇到null说明没有环，如果fast和slow相遇说明有环，进入4 其中一个指针移回链表头，另一个不动 两个指针每次移动一步，直到相遇，就是环的入口 完整代码如下： 12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode *detectCycle(ListNode *head) { ListNode* fast = head; ListNode* slow = head; while(fast &amp;&amp; fast-&gt;next &amp;&amp; fast-&gt;next-&gt;next){ fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; if(slow == fast){ fast = head; while(fast != slow){ fast = fast-&gt;next; slow = slow-&gt;next; } return fast; } } return nullptr; }};","link":"/2024/08/20/lc_141_%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8/"},{"title":"Installing GreenPlum &amp; Python3.7 on Ubuntu Server","text":"Installing GreenPlum &amp; Python3.7 on Linux(Ubuntu) ServerFirst, configure SSH 123# On the server side$ ls ./.ssh&gt; authorized_keys Copy the contents of your local id_rsa.pub into authorized_keys. Then you can directly connect using Xshell, and when selecting a private key, choose the corresponding id_rsa file. Installing GreenPlum12345$ sudo apt update$ sudo apt install software-properties-common$ sudo add-apt-repository ppa:greenplum/db$ sudo apt update$ sudo apt install greenplum-db-6 At this point, Greenplum has been installed. Let’s check the installed version: 12$ ls /optgreenplum-db-6.24.3 Configure environment variables: 123$ source /opt/greenplum-db-6.24.3/greenplum_path.sh$ which gpssh/opt/greenplum-db-6.24.3/bin/gpssh Copy the initialization file to the user directory: 123$ cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_singlenode .$ lsgpinitsystem_singlenode Write the hostname into a file: 12345$ hostnamenode0.dingzr.risb-pg0.utah.cloudlab.us# Create a new file hostlist_singlenode$ vim hostlist_singlenode# Paste the output of hostname into it Create the corresponding node directories: 1234$ mkdir greenplum$ cd greenplum$ mkdir primary master$ cd .. Modify the initialization file: 1234$ vim gpinitsystem_singlenode# declare -a DATA_DIRECTORY=(/users/dingzr/greenplum/primary /users/dingzr/greenplum/primary)# MASTER_HOSTNAME=node0.dingzr.risb-pg0.utah.cloudlab.us# MASTER_DIRECTORY=/users/dingzr/greenplum/master 12345678910111213$ gpssh-exkeys -f hostlist_singlenode[STEP 1 of 5] create local ID and authorize on local host[STEP 2 of 5] keyscan all hosts and update known_hosts file[STEP 3 of 5] retrieving credentials from remote hosts[STEP 4 of 5] determine common authentication file content[STEP 5 of 5] copy authentication files to all remote hosts[INFO] completed successfully$ gpinitsystem -c gpinitsystem_singlenode Test whether the installation was successful: 123456$ createdb demo$ psql demopsql (9.4.26)Type &quot;help&quot; for help.demo=# Installing Python 3.7Download the compressed package with wget: 1234$ wget https://www.python.org/ftp/python/3.7.9/Python-3.7.9.tgz$ tar -xzvf Python-3.7.9.tgz$ lsgpAdminLogs gpinitsystem_singlenode greenplum hostlist_singlenode Python-3.7.9 Python-3.7.9.tgz Enter the extracted Python folder, install dependencies, and build Python: 12345678910111213$ cd Python-3.7.9# Install dependencies (very important, otherwise you might encounter strange errors!)$ sudo apt-get install libbz2-dev libffi-dev libncurses5-dev libgdbm-dev liblzma-dev sqlite3 libsqlite3-dev openssl libssl-dev tcl8.6-dev tk8.6-dev libreadline-dev zlib1g-dev uuid-dev# Sometimes, after installing Python, you might encounter segmentation faults like &quot;for ifunc symbol `clock_gettime'&quot;. I solved it this way (reference: https://stackoverflow.com/questions/58077672/python3-relink-issue-while-importing-opencv):# $ sudo apt install python3-opencv# Compile. Note: you can specify a directory after --prefix, or leave it unset.$ ./configure --prefix=/usr/local/src/python37# Install$ sudo make &amp;&amp; sudo make install# Create symbolic links. Note: replace /usr/local/src/python37 with the directory you specified after --prefix$ sudo ln -s /usr/local/src/python37/bin/python3.7 /usr/bin/python3.7$ sudo ln -s /usr/local/src/python37/bin/pip3.7 /usr/bin/pip3.7 Then you need to re-source the environment and reset PYTHONHOME and PYTHONPATH, since they were modified by Greenplum: 123$ source /opt/greenplum-db-6.24.3/greenplum_path.sh$ unset PYTHONHOME$ unset PYTHONPATH Finally done! At least this worked for me. It’s quite troublesome, and if you run into other issues, I suggest googling them. 中文原文 Installing GreenPlum &amp; Python3.7 on Linux(Ubuntu) Server首先配置SSH 123# 在服务器端$ ls ./.ssh&gt; authorized_keys 将本机的id_rsa.pub内容复制到authorized_keys中 然后可以使用Xshell直接连接，选择私钥的时候选择配对的id_rsa文件即可 安装GreenPlum12345$ sudo apt update$ sudo apt install software-properties-common$ sudo add-apt-repository ppa:greenplum/db$ sudo apt update$ sudo apt install greenplum-db-6 此时已经安装好了，我们查看安装的版本 12$ ls /optgreenplum-db-6.24.3 配置环境变量 123$ source /opt/greenplum-db-6.24.3/greenplum_path.sh$ which gpssh/opt/greenplum-db-6.24.3/bin/gpssh 将初始化文件拷贝到用户目录下 123$ cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_singlenode .$ lsgpinitsystem_singlenode 将主机名写入文件 12345$ hostnamenode0.dingzr.risb-pg0.utah.cloudlab.us# 创建新文件hostlist_singlenode$ vim hostlist_singlenode# 将hostname的输出直接粘贴到里面 创建节点对应的文件夹 1234$ mkdir greenplum$ cd greenplum$ mkdir primary master$ cd .. 修改初始化文件 1234$ vim gpinitsystem_singlenode# declare -a DATA_DIRECTORY=(/users/dingzr/greenplum/primary /users/dingzr/greenplum/primary)# MASTER_HOSTNAME=node0.dingzr.risb-pg0.utah.cloudlab.us# MASTER_DIRECTORY=/users/dingzr/greenplum/master 12345678910111213$ gpssh-exkeys -f hostlist_singlenode[STEP 1 of 5] create local ID and authorize on local host[STEP 2 of 5] keyscan all hosts and update known_hosts file[STEP 3 of 5] retrieving credentials from remote hosts[STEP 4 of 5] determine common authentication file content[STEP 5 of 5] copy authentication files to all remote hosts[INFO] completed successfully$ gpinitsystem -c gpinitsystem_singlenode 测试是否安装成功 123456$ createdb demo$ psql demopsql (9.4.26)Type &quot;help&quot; for help.demo=# 安装python3.7wget工具下载压缩包 1234$ wget https://www.python.org/ftp/python/3.7.9/Python-3.7.9.tgz$ tar -xzvf Python-3.7.9.tgz$ lsgpAdminLogs gpinitsystem_singlenode greenplum hostlist_singlenode Python-3.7.9 Python-3.7.9.tgz 进入解压后的python文件夹，安装python依赖库，并编译安装python 12345678910111213$ cd Python-3.7.9# 安装依赖库（非常重要，不然有可能报各种奇奇怪怪的错！）$ sudo apt-get install libbz2-dev libffi-dev libncurses5-dev libgdbm-dev liblzma-dev sqlite3 libsqlite3-dev openssl libssl-dev tcl8.6-dev tk8.6-dev libreadline-dev zlib1g-dev uuid-dev# 有些时候安装完python后运行某些代码可能会出现for ifunc symbol `clock_gettime' segmentation fault这样的问题，我个人是这样解决的(参照这个帖子：https://stackoverflow.com/questions/58077672/python3-relink-issue-while-importing-opencv)：# $ sudo apt install python3-opencv# 编译，注意可以在--prefix后指定目录，也可以不指定$ ./configure --prefix=/usr/local/src/python37# 安装$ sudo make &amp;&amp; sudo make install# 链接，注意这里面的/usr/local/src/python37需要换成编译阶段--prefix后面指定的目录$ sudo ln -s /usr/local/src/python37/bin/python3.7 /usr/bin/python3.7$ sudo ln -s /usr/local/src/python37/bin/pip3.7 /usr/bin/pip3.7 然后需要重新source以下，并重设PYTHONHOME和PYTHONPATH，因为被greenplum改过 123$ source /opt/greenplum-db-6.24.3/greenplum_path.sh$ unset PYTHONHOME$ unset PYTHONPATH 终于弄好了，至少我是这样的，很麻烦，如果有别的问题建议google一下","link":"/2023/05/22/GreenPlum/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode - 239.Sliding Window Maximum","text":"LeetCode 239. Sliding Window MaximumProblem Link This is a very interesting problem. Let’s first think about what happens when the sliding window moves. If the number leaving the window is not the maximum of the previous window, no problem—it can just be discarded. If the number leaving the window happens to be the maximum, then a new “king” takes its place. How do we quickly and accurately find this new maximum? For the first case, if the number is not the maximum, it means there is a larger number later in the window. When the window moves, this smaller number will be discarded first, but it does not affect the maximum because there are larger numbers remaining. Such numbers do not impact the result—they are “invisible” in the window, and we can ignore them. The second case is numbers for which no larger number exists later in the window. These are the ones that really matter for computing the sliding window maximum. We need to record all such numbers. A monotonic queue is perfect for this scenario combined with the sliding window structure (where each move introduces a new number at the back and removes a number from the front). In a monotonic queue, elements decrease from the front to the back. Each time a new number comes in: Compare it with the back of the queue. If the back is smaller than the new number, it is discarded (“invisible”). Continue until the back is not smaller than the new number. Push the new number to the back. When the window moves, the first element may leave the window. If the leaving element is at the front of the queue (the current maximum), it must be removed from the queue. (To handle duplicates, store indices in the queue.) The maximum element of the current window is always at the front of the queue. Complete code: 1234567891011121314151617181920212223242526272829303132333435363738class Solution {public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) { deque&lt;int&gt; dq; int left = 0; vector&lt;int&gt; ans; for(int i = 0; i &lt; nums.size() - k + 1; i++){ if(i == 0){ // Initialize the monotonic queue for the first window for(int j = 0; j &lt; k; j++){ if(dq.empty() || nums[dq.back()] &gt;= nums[j]){ dq.push_back(j); } else{ while(!dq.empty() &amp;&amp; nums[dq.back()] &lt; nums[j]){ dq.pop_back(); } dq.push_back(j); } } ans.push_back(nums[dq.front()]); } else{ if(!dq.empty() &amp;&amp; dq.front() == i - 1){ dq.pop_front(); } if(dq.empty() || nums[dq.back()] &gt;= nums[i+k-1]){ dq.push_back(i+k-1); } else{ while(!dq.empty() &amp;&amp; nums[dq.back()] &lt; nums[i+k-1]){ dq.pop_back(); } dq.push_back(i+k-1); } ans.push_back(nums[dq.front()]); } } return ans; }}; 中文原文 LeetCode 239. 滑动窗口最大值题目链接 非常有趣的一道题。我们首先思考一下，每次窗口移动可能会发生什么事。 假如移出去的那个数不是之前窗口的最大值，那没问题，直接丢掉就可以。 假如移出去的恰好就是窗口的最大值，那么把它移走了，新王登基，怎样又快又准地去找这个新王是谁呢？ 我们来看第一种情况，如果这个数不是最大值，说明后面一定存在一个数比它更大。当窗口移动时，由于这个数在前面，所以先被卡掉，但是因为后面还有更大的，所以卡掉它对于窗口的最大值不起任何影响。因此这种数对于结果起不到任何的改变，是窗口中的小透明，我们不需要管它们。 那么剩下的另一种数就是窗口的后面没有比它大的了，这种才是我们需要考虑的，因为它们是真正关乎到滑动窗口最大值的数。 我们要记录所有的这种数，这样的单调序列再加上滑动窗口这种每次后面进来一个数，前面出来一个数的结构，非常适合使用单调队列来记录。单调队列中，元素从队头到队尾递减，每次后移一位，就对比新的数和队尾，如果队尾比新数小，就说明队尾是小透明，出队扔掉，再比较新的队尾，也就是本来在队尾的前一位，比队尾大一点，如此循环直到队尾不比新数小，也就是踢到了钢板。这时将新数入队。 同时，移动窗口会导致原来窗口中的第一位被卡掉，这时如果被卡掉的正好是队头，那说明它恰好是最大的那个，就需要从队头把它出队。（由于可能有重复值，因此队列中需要存储下标，通过下标进行比对） 每个窗口中最大的元素一定就是当前的队头。 综合以上，完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839class Solution {public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) { deque&lt;int&gt; dq; int left = 0; vector&lt;int&gt; ans; for(int i = 0; i &lt; nums.size() - k + 1; i++){ if(i == 0){ //首先建立第一个窗口的优先队列，后续的优先队列都在此基础上调整 for(int j = 0; j &lt; k; j++){ cout&lt;&lt;j&lt;&lt;endl; if(dq.empty() || nums[dq.back()] &gt;= nums[j]){ dq.push_back(j); } else{ while(!dq.empty() &amp;&amp; nums[dq.back()] &lt; nums[j]){ dq.pop_back(); } dq.push_back(j); } } ans.push_back(nums[dq.front()]); } else{ if(!dq.empty() &amp;&amp; dq.front() == i - 1){ dq.pop_front(); } if(dq.empty() || nums[dq.back()] &gt;= nums[i+k-1]){ dq.push_back(i+k-1); } else{ while(!dq.empty() &amp;&amp; nums[dq.back()] &lt; nums[i+k-1]){ dq.pop_back(); } dq.push_back(i+k-1); } ans.push_back(nums[dq.front()]); } } return ans; }};","link":"/2024/07/28/lc_239_%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%80%E5%A4%A7%E5%80%BC/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 25. Reverse Nodes in k-Group","text":"LeetCode 25. Reverse Nodes in k-GroupProblem Link This is a tricky problem and requires some careful thinking. We have already solved LeetCode 206: Reverse Linked List, where the idea is to keep a previous node and, in each step, point the next of the current node to the previous node. In this problem, the reversal within each group of k nodes can be handled similarly. The main difficulty is how to connect the locally reversed sublist back to the original list. Here’s a rough illustration (assuming k=2): A tricky part here is setting prev. To determine the last node of a group of k nodes, we use a fast and slow pointer. The fast pointer is k nodes ahead of the slow pointer, and both move k nodes each iteration. The slow pointer points to the node before the current k nodes (its next points to the first node of the group), while the fast pointer points to the last node of the current group. When reversing the first group, prev is set to nullptr because the original first node becomes the last node, which should point to null. However, for each group, after the first node becomes the last node, it needs to point to the head of the next group, so prev should initially point to fast-&gt;next before starting the reversal of the group. After reversing a group, the tail of the group is already connected to the next group. But note that the head of each group changes after reversal. After traversal, the previous group’s tail should point to the new head of the reversed group. The new head is the position of prev after reversal, and the previous tail is slow. So we need slow-&gt;next = prev. It’s a bit tricky, so looking at the diagram helps. Complete code is as follows: 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */class Solution {public: ListNode* reverseKGroup(ListNode* head, int k) { ListNode dummy(0); dummy.next = head; ListNode* fast = &amp;dummy; ListNode* slow = fast; while(fast){ for(int i = 0; i &lt; k; i++){ if(!fast-&gt;next) return dummy.next; fast = fast-&gt;next; } ListNode* prev = fast-&gt;next; ListNode* cur = slow-&gt;next; while(prev != fast){ ListNode* tmp = cur-&gt;next; cur-&gt;next = prev; prev = cur; cout&lt;&lt;cur-&gt;val&lt;&lt;endl; cur = tmp; } ListNode* newEnd = slow-&gt;next; newEnd-&gt;next = cur; slow-&gt;next = fast; slow = fast = newEnd; } return dummy.next; }}; 中文原文 [LeetCode hot 100] 25. k个一组翻转链表题目链接 这道题要想明白还真是得费一些脑筋。 我们已经做过LeetCode 206 反转链表，直到反转链表的思路是保留一个前驱节点，然后每次让后继结点的next指向前驱节点。这个题中对于每一组中的反转自然也可以这样做。 不过难点就在于局部反转后怎样和原链表接起来。思路我大致画了个图（假设k=2）： 这里有个很tricky的点，就是这个prev的设置。由于我们需要确定一组k个节点中的最后一个，所以需要使用快慢指针，快指针比慢指针领先k，并且二者每轮同时后移k个。慢指针是当前k个的前一个，也就是next指向当前k个中第一个的节点，而快指针就是当前k个的最后一个。在反转整个链表时，我们首先令prev=nullptr，这是因为原先的第一个节点会变成最后一个，而最后一个节点的next指向的就是null。但是这里不同，我们每一组的第一个节点变成最后一个节点后，还需要指向下一组的头，所以prev在每组开始反转的时候都应该先指向下一组的头，那么这个下一组的头就是fast-&gt;next。 每组反转之后，这一组的尾就已经接在下一组的头上了，但是注意，每一组的头都会变的，所以在遍历之后应该让上一组的尾重新指向这个新的头。新的头就是反转结束后prev的位置，而上一组的尾就是slow，所以需要slow-&gt;next = prev; 挺绕的，还是看图好懂一点吧~ 完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */class Solution {public: ListNode* reverseKGroup(ListNode* head, int k) { ListNode dummy(0); dummy.next = head; ListNode* fast = &amp;dummy; ListNode* slow = fast; while(fast){ for(int i = 0; i &lt; k; i++){ if(!fast-&gt;next) return dummy.next; fast = fast-&gt;next; } ListNode* prev = fast-&gt;next; ListNode* cur = slow-&gt;next; while(prev != fast){ ListNode* tmp = cur-&gt;next; cur-&gt;next = prev; prev = cur; cout&lt;&lt;cur-&gt;val&lt;&lt;endl; cur = tmp; } ListNode* newEnd = slow-&gt;next; newEnd-&gt;next = cur; slow-&gt;next = fast; slow = fast = newEnd; } return dummy.next; }};","link":"/2024/07/28/lc_25_k%E4%B8%AA%E4%B8%80%E7%BB%84%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 46. Permutations","text":"LeetCode 46. PermutationsWhen I first saw this problem, I felt like the answer was right at my fingertips, but after trying to write it, something felt off. The reason is that this is a backtracking problem. According to the definition from Baidu Encyclopedia: Backtracking, also called trial-and-error, is based on the idea of starting from a certain state (initial state) of a problem, searching all possible states reachable from this state. When a path reaches a “dead end” (cannot proceed further), it backtracks one or more steps and continues searching from another possible state, until all paths (states) have been tried. This method of constantly “advancing” and “backtracking” to find a solution is called backtracking. The key characteristic of backtracking is that it is top-down: starting from nothing at the top and gradually exploring deeper, with the answers obtained at the bottom level. For this problem, at the beginning we know nothing. Suppose we have the sequence [1, 2, 3]. We first decide the first number: [1], [2], or [3]. If the first number is 1, the second number can be [1, 2] or [1, 3], and then the third number is determined. Once we choose the third number, we have obtained a complete permutation, which should immediately be added to the answer set. In other words, although we use recursion, it mainly serves as a stack-like mechanism to backtrack; the answers are obtained at the bottom, not at the top. Here is the implementation: 1234567891011121314151617181920212223242526272829class Solution {public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) { vector&lt;vector&lt;int&gt;&gt; ans; vector&lt;int&gt; cur; int* visited = new int[nums.size()]{0}; backtrack(nums, cur, visited, ans); return ans; } void backtrack(vector&lt;int&gt;&amp; nums, vector&lt;int&gt; cur, int* visited, vector&lt;vector&lt;int&gt;&gt;&amp; ans){ if(cur.size() == nums.size()) { // Reached the bottom, obtain a complete permutation and add to results ans.push_back(cur); return; } for(int i = 0; i &lt; nums.size(); i++){ if(visited[i] == 0){ // Explore one layer deeper cur.push_back(nums[i]); visited[i] = 1; backtrack(nums, cur, visited, ans); // Backtrack to the current layer visited[i] = 0; cur.pop_back(); } } }}; 中文原文 [LeetCode hot 100] 46. 全排列Permutation拿到这道题的时候总感觉答案就在嘴边，但是写了写就感觉怎么都不对劲，原因是没有意识到这是一个回溯题。所谓回溯算法，百度百科给出的定义是： 回溯法也称试探法，它的基本思想是：从问题的某一种状态（初始状态）出发，搜索从这种状态出发所能达到的所有“状态”，当一条路走到“尽头”的时候（不能再前进），再后退一步或若干步，从另一种可能“状态”出发，继续搜索，直到所有的“路径”（状态）都试探过。这种不断“前进”、不断“回溯”寻找解的方法，就称作“回溯法”。 回溯算法最大的特征就是它是自顶向下的，也就是从顶部的什么都没有，慢慢往深处探索，在最底端得到答案。 对于这道题而言，一开始是什么都不知道的，假如说有个序列[1, 2, 3]，首先确定出第一个数，可以是[1]，可以是[2]，可以是[3]。当第一个数为1时，再确定第二个数，可以是[1, 2]或[1, 3]，然后确定第三个数。当我们确定第三个数之后的时候，实际上是已经得到了两个答案，就应该把这两个答案立即加到答案集合中。也就是说，我们写出来虽然也是递归的形势，但是只是用递归实现了类似栈的回退作用，答案并不是在最顶层得到，而是在最底层得到。 具体如何操作请见代码。 123456789101112131415161718192021222324252627282930class Solution {public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) { vector&lt;vector&lt;int&gt;&gt; ans; vector&lt;int&gt; cur; int* visited = new int[nums.size()]{0}; backtrack(nums, cur, visited, ans); return ans; } void backtrack(vector&lt;int&gt;&amp; nums, vector&lt;int&gt; cur, int* visited, vector&lt;vector&lt;int&gt;&gt;&amp; ans){ if(cur.size() == nums.size()) { //探到最底层，得到一个答案，放到结果中 ans.push_back(cur); return; } for(int i = 0; i &lt; nums.size(); i++){ if(visited[i] == 0){ //往下探索一层 cur.push_back(nums[i]); visited[i] = 1; backtrack(nums, cur, visited, ans); //回到当前这一层 visited[i] = 0; cur.pop_back(); } } }};","link":"/2024/06/15/lc_46_%E5%85%A8%E6%8E%92%E5%88%97/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 146. LRU Cache","text":"LeetCode 146. LRU CacheProblem Link This is a high-frequency problem. To achieve O(1) time complexity for get operations, a hash table is naturally used. However, we also need O(1) time for deletion (eviction) and reordering. Using a doubly linked list is appropriate because it allows convenient deletion. In a traditional singly linked list, deleting a node requires traversing to find the predecessor, whereas a doubly linked list keeps a reference to the previous node, allowing direct deletion. Combining both, the hash table stores &lt;key, node&gt; pairs so that we can quickly find the corresponding node and move it. Additionally, to perform operations like moving a node to the head or deleting the tail node, we establish a dedicated head and tail node—not just head/tail pointers. Complete code: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172struct BiListNode{ int key; int value; BiListNode* prev; BiListNode* next; BiListNode(int key, int value):key(key), value(value){}};class LRUCache {private: BiListNode* head; BiListNode* tail; int capacity; int usage; unordered_map&lt;int, BiListNode*&gt; keyMap;public: LRUCache(int capacity) { this-&gt;head = new BiListNode(0, 0); this-&gt;tail = new BiListNode(0, 0); head-&gt;next = tail; tail-&gt;prev = head; head-&gt;prev = tail-&gt;next = nullptr; this-&gt;capacity = capacity; this-&gt;usage = 0; } int get(int key) { if(!keyMap.count(key)) return -1; BiListNode* entry = keyMap[key]; // Remove from current position entry-&gt;prev-&gt;next = entry-&gt;next; entry-&gt;next-&gt;prev = entry-&gt;prev; head-&gt;next-&gt;prev = entry; // Move to head entry-&gt;next = head-&gt;next; head-&gt;next = entry; entry-&gt;prev = head; return entry-&gt;value; } void put(int key, int value) { if(!keyMap.count(key)){ if(usage &gt;= capacity){ // Delete tail node and remove from hash map BiListNode* tmp = tail-&gt;prev; keyMap.erase(tmp-&gt;key); tail-&gt;prev-&gt;prev-&gt;next = tail; tail-&gt;prev = tmp-&gt;prev; delete tmp; usage--; } // Insert new node at head BiListNode* entry = new BiListNode(key, value); entry-&gt;next = head-&gt;next; entry-&gt;prev = head; entry-&gt;next-&gt;prev = entry; head-&gt;next = entry; keyMap.emplace(key, entry); usage++; } else{ BiListNode* entry = keyMap[key]; entry-&gt;value = value; // Update value // Move to head entry-&gt;prev-&gt;next = entry-&gt;next; entry-&gt;next-&gt;prev = entry-&gt;prev; entry-&gt;next = head-&gt;next; head-&gt;next-&gt;prev = entry; head-&gt;next = entry; entry-&gt;prev = head; } }}; 中文原文 LeetCode 146. LRU缓存题目链接 也是高频题目了，为了使查询get达到O(1)，自然是用哈希表来存储，但是又需要在O(1)时间完成删除（即逐出）、调整顺序等操作。这里使用双向链表比较合适，主要是因为比较方便删除。传统的单向链表想要删除还需要再遍历一遍获取前驱节点，而双向链表自带前驱节点，可以不用遍历就直接删除。 将二者结合，则哈希表应该保存&lt;key, 链表节点&gt;这样的键值对，这样可以通过key直接找到对应的节点，方便移位。 另外为了实现放到头部和删除尾部元素这两个操作，需要建立头结点和尾节点，注意不是头指针和尾指针，而是单独的头节点和尾节点。 完整代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980struct BiListNode{ int key; int value; BiListNode* prev; BiListNode* next; BiListNode(int key, int value):key(key), value(value){}};class LRUCache {private: BiListNode* head; BiListNode* tail; int capacity; int usage; unordered_map&lt;int, BiListNode*&gt; keyMap;public: LRUCache(int capacity) { this-&gt;head = new BiListNode(0, 0); this-&gt;tail = new BiListNode(0, 0); head-&gt;next = tail; tail-&gt;prev = head; head-&gt;prev = tail-&gt;next = nullptr; this-&gt;capacity = capacity; this-&gt;usage = 0; } int get(int key) { if(!keyMap.count(key)) return -1; BiListNode* entry = keyMap[key]; //从原本位置拿走 entry-&gt;prev-&gt;next = entry-&gt;next; entry-&gt;next-&gt;prev = entry-&gt;prev; head-&gt;next-&gt;prev = entry; //放到头部 entry-&gt;next = head-&gt;next; head-&gt;next = entry; entry-&gt;prev = head; return entry-&gt;value; } void put(int key, int value) { if(!keyMap.count(key)){ if(usage &gt;= capacity){ //删除尾部元素，注意在哈希表里也要删除 BiListNode* tmp = tail-&gt;prev; keyMap.erase(tmp-&gt;key); tail-&gt;prev-&gt;prev-&gt;next = tail; tail-&gt;prev = tmp-&gt;prev; delete tmp; usage--; } //在头部插入新元素 BiListNode* entry = new BiListNode(key, value); entry-&gt;next = head-&gt;next; entry-&gt;prev = head; entry-&gt;next-&gt;prev = entry; head-&gt;next = entry; keyMap.emplace(key, entry); usage++; } else{ BiListNode* entry = keyMap[key]; entry-&gt;value = value; //更新value值 //放到头部 entry-&gt;prev-&gt;next = entry-&gt;next; entry-&gt;next-&gt;prev = entry-&gt;prev; entry-&gt;next = head-&gt;next; head-&gt;next-&gt;prev = entry; head-&gt;next = entry; entry-&gt;prev = head; } }};/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */","link":"/2024/07/28/lc_146_LRU%E7%BC%93%E5%AD%98/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; leetcode hot100 - 128.Longest Consecutive Sequence","text":"LeetCode 128. Longest Consecutive SequenceProblem Link When facing this problem, first think about how a human would approach it. Typically, we would see a number and check the whole sequence for consecutive numbers. If there are, we continue checking, picking numbers one by one to calculate the length, right? To simplify, we don’t need to start from every number; we only need to start from the beginning of a consecutive sequence. First, traverse the array and insert elements into a set. This removes duplicates and makes lookups convenient. Traverse the set. For each element e, if e-1 exists in the set, skip it because e is not the start of a consecutive sequence. If e-1 does not exist in the set, then e is the start of a consecutive sequence. Start checking e+1, e+2, ..., e+n until e+n does not exist. The length of the sequence is n. After traversing the whole set, the maximum sequence length is the answer. 1234567891011121314151617181920class Solution {public: int longestConsecutive(vector&lt;int&gt;&amp; nums) { set&lt;int&gt; numSet; for(auto&amp; num : nums){ numSet.emplace(num); } int maxLength = 0; for(auto&amp; num : numSet){ if(numSet.count(num-1)) continue; int len = 0; while(numSet.count(num+len)){ len++; } maxLength = max(maxLength, len); } return maxLength; }}; 中文原文 [LeetCode hot 100] 128. 最长连续序列题目链接 遇到这种题，首先想一想，作为一个人类，我们怎么思考这个问题。我们肯定是每看到一个数就去整个序列里面找有没有挨着的，如果有，那就顺着继续找，最后一个数一个数地摘出来，算一个长度对吗？ 简化这个过程，我们不需要每个数都找，而是只需要从一个连续序列开头的那个数往后找就行。 首先先遍历一下这个数组，并且放入集合中，一来是去重，二来是方便后面的查找。 遍历这个集合，对于每个元素e，如果集合中存在比它小1的元素e-1，那就先不管这个数，因为肯定不是一个连续序列的开头。 如果集合中不存在e-1，就说明e一定是一个连续序列的开头，那么就开始找e+1, e+2, …, e+n，直到e+n找不到了，说明序列到此结束，当前序列的长度就是n。 最后遍历完之后输出序列长度的最大值就行。 1234567891011121314151617181920class Solution {public: int longestConsecutive(vector&lt;int&gt;&amp; nums) { set&lt;int&gt; numSet; for(auto&amp; num : nums){ numSet.emplace(num); } int maxLength = 0; for(auto&amp; num : numSet){ if(numSet.count(num-1)) continue; int len = 0; while(numSet.count(num+len)){ len++; } maxLength = max(maxLength, len); } return maxLength; }};","link":"/2024/07/24/lc_128_%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode - 53. Maximum Subarray","text":"LeetCode 53. Maximum SubarrayProblem Link For this problem, the approach is based on dynamic programming. We create an array maxSum where maxSum[i] represents the maximum subarray sum ending at index i. The logic is: If the previous maximum subarray sum maxSum[i-1] is positive, it contributes positively to maxSum[i], so we add nums[i]. Otherwise, it’s better to start a new subarray from nums[i]. Thus: 1maxSum[i] = max(maxSum[i-1] + nums[i], nums[i]) Finally, take the maximum value among all maxSum[i]. 1234567891011121314class Solution {public: int maxSubArray(vector&lt;int&gt;&amp; nums) { vector&lt;int&gt; maxSum(nums.size()); int ans = INT_MIN; for(int i = 0; i &lt; nums.size(); i++){ if(i == 0) maxSum[i] = nums[i]; else maxSum[i] = max(maxSum[i - 1] + nums[i], nums[i]); ans = max(ans, maxSum[i]); } return ans; }}; 中文原文 [LeetCode hot 100] 53. 最大子数组和题目链接 不说思路了，直接说算法流程。 建立一个新的数组maxSum，这个数组下标为i的位置maxSum代表：nums数组中，以第i个数为结尾的子数组之和的最大值。这时就可以利用类似于前缀和的思路。假如我们已经得到了以第i-1个数为结尾的子数组之和的最大值即maxSum[i-1]，那么以第i位为结尾的子数组之和最大值maxSum[i]一定能够推出来。maxSum[i]的唯一也是最大的要求就是必须包含nums[i]，那么是否包含前面的其他数，其实maxSum[i-1]已经提前算过了。假如maxSum[i-1]大于0，就说明前面选出来的子数组是有正向增益的，要加上才能更大，因此maxSum[i] = maxSum[i-1] + nums[i]。否则就说明以nums[i-1]结尾的子数组里面，和最大也没有大于0的，那干嘛还要再带着这些累赘呢，因此这种情况下maxSum[i] = nums[i] 完整代码如下 1234567891011121314class Solution {public: int maxSubArray(vector&lt;int&gt;&amp; nums) { vector&lt;int&gt; maxSum(nums.size()); int ans = INT_MIN; for(int i = 0; i &lt; nums.size(); i++){ if(i == 0) maxSum[i] = nums[i]; else maxSum[i] = max(maxSum[i - 1] + nums[i], nums[i]); ans = max(ans, maxSum[i]); } return ans; }};","link":"/2024/07/28/lc_53_%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%E5%92%8C/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 94.Binary Tree Inorder Traversal (with non-recursive pre&#x2F;in&#x2F;postorder traversal)","text":"[LeetCode Hot 100] 94. Binary Tree Inorder TraversalProblem Link Inorder Traversal (Non-Recursive)Inorder traversal follows the order: left subtree → root → right subtree. To implement it non-recursively, we use a stack to save root nodes. After finishing the left subtree, pop the root from the stack and then traverse the right subtree. The main idea: Use a pointer cur to track the current node, instead of relying on the stack top. While cur exists, push it to the stack and move to cur-&gt;left. When cur becomes null, pop from the stack, visit the node, and move to its right child. 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: vector&lt;int&gt; inorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; TreeNode* cur = root; while(cur || !st.empty()){ while(cur){ st.push(cur); cur = cur-&gt;left; } cur = st.top(); st.pop(); ans.push_back(cur-&gt;val); cur = cur-&gt;right; } return ans; }}; Preorder Traversal (Non-Recursive)Preorder traversal is simpler since we just need to push the right child first, then the left child. Each iteration, the top of the stack is the current node. 1234567891011121314151617class Solution {public: vector&lt;int&gt; preorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; st.push(root); while(!st.empty()){ TreeNode* cur = st.top(); st.pop(); if(!cur) continue; ans.push_back(cur-&gt;val); if(cur-&gt;right) st.push(cur-&gt;right); if(cur-&gt;left) st.push(cur-&gt;left); } return ans; }}; Postorder Traversal (Non-Recursive)Key: track the last visited node prev. A node can only be visited when: It has no children, or Its children have already been visited. Otherwise, push its right and left children to the stack. 12345678910111213141516171819202122class Solution {public: vector&lt;int&gt; postorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; if(!root) return ans; st.push(root); TreeNode* prev = nullptr; while(!st.empty()){ TreeNode* cur = st.top(); if((!cur-&gt;left &amp;&amp; !cur-&gt;right) || (prev &amp;&amp; (prev == cur-&gt;left || prev == cur-&gt;right))){ st.pop(); ans.push_back(cur-&gt;val); prev = cur; } else{ if(cur-&gt;right) st.push(cur-&gt;right); if(cur-&gt;left) st.push(cur-&gt;left); } } return ans; }}; Postorder Using Modified PreorderPreorder traversal with left and right swapped gives a sequence that is the reverse of postorder. After performing modified preorder, reverse the result to get postorder. 123456789101112131415161718class Solution {public: vector&lt;int&gt; postorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; if(!root) return ans; st.push(root); while(!st.empty()){ TreeNode* cur = st.top(); st.pop(); ans.push_back(cur-&gt;val); if(cur-&gt;left) st.push(cur-&gt;left); if(cur-&gt;right) st.push(cur-&gt;right); } reverse(ans.begin(), ans.end()); // reverse to get postorder return ans; }}; 中文原文 [LeetCode hot 100] 94. 二叉树中序遍历题目链接 这里我们主要说非递归。 由于中序遍历是左子树-根-右子树的顺序，因此我们在设计算法的时候需要使用栈保存根节点，当左子树遍历完了，再将根节点出栈，然后访问右子树。 我们直观的想法就是：首先把根节点进栈，然后左孩子进栈，直到把左子树处理完了之后把根节点露出来，然后输出根节点，根节点出栈，根节点的右孩子入栈。这玩意咋用循环迭代实现呢？把根节点拿出来访问右子树这个都会，问题是左子树入栈该遵循一个什么原则呢？理论上我们每次循环判断当前节点如果有左子树就入栈不就行了？ 但是有个问题就是我们不能在出栈的时候再判断有没有左孩子，也就是说找左孩子的活不能从栈顶拿元素再判断，那样的话如果发现有左孩子，你的根节点（也就是现在的栈顶）就不能出栈，但是你最后左子树搞了一圈之后就会发现，栈顶又变成这个根节点了，由于每次循环的判定逻辑都是一样的，所以它的左孩子又会入栈，就成了死循环。 因此，需要有一个指针来记录当前遍历到的节点，而不是依靠栈顶元素，不然乱套了。每次当前节点有左孩子，就先将当前节点入栈，然后将指针指向左孩子，此时将当前节点入栈的操作代表“我记住你了，待会儿再来遍历你和你的右子树”。不断地将指针指向左孩子，其实就是不断记忆的过程，因为一旦一个节点有左孩子，就要优先处理左子树，先记住根节点和右子树，过后再说。 直到我们遇到了null，说明终于没有更下一层的左子树了，该遍历中间节点和右子树了，而中间节点现在就在栈顶，这不就好办了吗？ 代码如下，实在理解不了咱就直接背下来吧，别折磨自己了，这博客我写了一小时还没法用流畅的语言表达出来，真吐了。怪不得程序员当久了语言功能会退化。 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */class Solution {public: vector&lt;int&gt; inorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; TreeNode* cur = root; while(cur || !st.empty()){ while(cur){ st.push(cur); cur = cur-&gt;left; } cur = st.top(); st.pop(); ans.push_back(cur-&gt;val); cur = cur-&gt;right; } return ans; }}; 前序遍历非递归那顺便来说一下前序遍历的非递归实现。这个就简单很多，因为不用保存根节点，省去了很多麻烦事，直接把右孩子和左孩子先后入栈即可，每次循环，栈顶元素就是当前节点 12345678910111213141516171819class Solution {public: vector&lt;int&gt; preorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; st.push(root); while(!st.empty()){ TreeNode* cur = st.top(); ans.push_back(cur-&gt;val); if(cur-&gt;right){ st.push(cur-&gt;right); } if(cur-&gt;left){ st.push(cur-&gt;left); } } return ans; }}; 后序遍历非递归后序遍历的关键之关键之关键是要保存一下上一次访问的节点，因为虽然先访问的是根节点，但是根节点却不能出栈。为了在访问栈顶结点的时候方便判断是左子树右子树都遍历完了还是都没有遍历，需要保存上一个访问的节点，如果上一个访问的是左孩子或右孩子，那就说明需要访问根节点并且出栈，否则就说明需要将左右孩子入栈。 1234567891011121314151617181920212223242526class Solution {public: vector&lt;int&gt; postorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; if(!root) return ans; st.push(root); TreeNode* prev = nullptr; while(!st.empty()){ TreeNode* cur = st.top(); if((!cur-&gt;left &amp;&amp; !cur-&gt;right) || prev &amp;&amp; (prev == cur-&gt;left || prev == cur-&gt;right)){ st.pop(); ans.push_back(cur-&gt;val); prev = cur; } else{ if(cur-&gt;right){ st.push(cur-&gt;right); } if(cur-&gt;left){ st.push(cur-&gt;left); } } } return ans; }}; 事实上还有一种更讨巧的算法，那就是前序遍历只要把左右子树的顺序换一下，就刚好与后序遍历的序列相反。因此可以用前序遍历来构造后序遍历。 1234567891011121314151617181920class Solution {public: vector&lt;int&gt; preorderTraversal(TreeNode* root) { stack&lt;TreeNode*&gt; st; vector&lt;int&gt; ans; st.push(root); while(!st.empty()){ TreeNode* cur = st.top(); ans.push_back(cur-&gt;val); if(cur-&gt;left){ st.push(cur-&gt;left); } if(cur-&gt;right){ st.push(cur-&gt;right); } } reverse(ans.begin(), ans.end()); //反转后就是后续遍历的序列 return ans; }};","link":"/2024/07/28/lc_94_%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode - 695.Max Area of Island","text":"LeetCode 695. Max Area of IslandProblem Link This is a commonly tested problem. It is well-suited for DFS. Starting from each point, we perform a depth-first search in all four directions. We maintain a visited array to mark whether each point has already been visited—if it has, we skip it to avoid double counting. If we encounter a 0 or go out of bounds, we return 0. Otherwise, the area is the sum of the areas from the four directions plus 1 (for the current cell itself). If we visit an already visited cell, we also return 0, meaning either it’s a duplicate visit during the current calculation, or it has already been counted from another starting point. Complete code: 12345678910111213141516171819202122232425262728class Solution {public: int dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int idx1, int idx2, vector&lt;vector&lt;bool&gt;&gt;&amp; visited){ if(idx1 &lt; 0 || idx1 &gt;= grid.size() || idx2 &lt; 0 || idx2 &gt;= grid[0].size()){ return 0; } if(visited[idx1][idx2] || grid[idx1][idx2] == 0) return 0; visited[idx1][idx2] = true; return dfs(grid, idx1 - 1, idx2, visited) + dfs(grid, idx1 + 1, idx2, visited) + dfs(grid, idx1, idx2 - 1, visited) + dfs(grid, idx1, idx2 + 1, visited) + 1; } int maxAreaOfIsland(vector&lt;vector&lt;int&gt;&gt;&amp; grid) { vector&lt;vector&lt;bool&gt;&gt; visited; for(int i = 0; i &lt; grid.size(); i++){ vector&lt;bool&gt; tmp(grid[0].size(), false); visited.push_back(tmp); } int maxArea = 0; for(int i = 0; i &lt; grid.size(); i++){ for(int j = 0; j &lt; grid[0].size(); j++){ maxArea = max(maxArea, dfs(grid, i, j, visited)); } } return maxArea; }}; 中文原文 LeetCode 695. 岛屿的最大面积题目链接 我看这还是一个常考的题目。这种题适合用dfs，从每一个点向四周深度优先搜索，用一个visited数组保存每个点是否被访问过，如果访问过就不要重复计算了。如果访问到0，或者到界外了，就返回0，否则就是上下左右的面积之和再+1（自己本身还占一格）。遇到访问过的也是直接返回0，表示要么在这一次计算中重复访问了，要么就是之前在从别的点开始计算时已经计算过了。 完整代码如下： 123456789101112131415161718192021222324252627282930class Solution {public: int dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int idx1, int idx2, vector&lt;vector&lt;bool&gt;&gt;&amp; visited){ if(idx1 &lt; 0 || idx1 &gt;= grid.size() || idx2 &lt; 0 || idx2 &gt;= grid[0].size()){ return 0; } if(visited[idx1][idx2] || grid[idx1][idx2] == 0) return 0; // cout&lt;&lt;idx1&lt;&lt;&quot;,&quot;&lt;&lt;idx2&lt;&lt;endl; visited[idx1][idx2] = true; return dfs(grid, idx1 - 1, idx2, visited) + dfs(grid, idx1 + 1, idx2, visited) + dfs(grid, idx1, idx2 - 1, visited) + dfs(grid, idx1, idx2 + 1, visited) + 1; } int maxAreaOfIsland(vector&lt;vector&lt;int&gt;&gt;&amp; grid) { vector&lt;vector&lt;bool&gt;&gt; visited; for(int i = 0; i &lt; grid.size(); i++){ vector&lt;bool&gt; tmp(grid[0].size(), false); visited.push_back(tmp); } int maxArea = 0; for(int i = 0; i &lt; grid.size(); i++){ for(int j = 0; j &lt; grid[0].size(); j++){ maxArea = max(maxArea, dfs(grid, i, j, visited)); } } return maxArea; }};","link":"/2024/06/15/lc_695_%E6%9C%80%E5%A4%A7%E5%B2%9B%E5%B1%BF%E9%9D%A2%E7%A7%AF/"},{"title":"&lt;Data Structure&#x2F;Algorithm&gt; 2.归并排序Merge Sort","text":"归并排序Merge Sort归并排序个人感觉理解起来没什么难度，主要就是一个递归地合并子序列的过程，直接写代码，在代码特殊的地方说明一下 12345678910111213141516171819202122232425262728293031323334#include&lt;bits/stdc++.h&gt;#include&lt;vector&gt;using namespace std;void merge(vector&lt;int&gt; &amp;arr, int left, int mid, int right){ vector&lt;int&gt; tmp(right - left + 1); int pl = left, pr = mid; while(pl &lt;= mid - 1 &amp;&amp; pr &lt;= right){ if(arr[pl] &lt; arr[pr]){ tmp.push_back(arr[pl++]); } else{ tmp.push_back(arr[pr++]); } } //下面这两个循环只会执行一个，因为不可能左右子列都有元素剩余 while(pl &lt;= mid - 1){ tmp.push_back(arr[pl++]); } while(pr &lt;= right){ tmp.push_back(arr[pr++]); } int j = 0; for(int i = left; i &lt;= right; i++){ arr[i] = tmp[j++]; }}void mergeSort(vector&lt;int&gt; &amp;arr, int left, int right){ if(left &gt;= right) return; int mid = (left + right) / 2; mergeSort(arr, left, mid - 1); mergeSort(arr, mid, right);}","link":"/2024/06/12/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8FMergeSort/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 48. Rotate Image","text":"LeetCode 48. Rotate ImageProblem Link Approach 1: Rotate Layer by LayerThis problem can be tricky. Initially, it reminded me of rotating an array using multiple reversals, but it can also be rotated layer by layer with O(1) space complexity. Here’s the idea: For a given layer, we can divide it into four edges: top, right, bottom, and left. During rotation: Top → Right Right → Bottom Bottom → Left Left → Top If we rotate by edge, we need an O(N) array. To achieve O(1) space, rotate one element at a time and track the correspondence of positions among the four edges. For the i-th layer from the outermost, 0 &lt;= i &lt; n/2 (works for odd n as the innermost element doesn’t need rotation).For the j-th element in the current layer, 0 &lt;= j &lt; n - 2*i - 1 (subtract 1 to avoid over-rotating). Top element: (i, i+j) Right element: (i+j, n-1-i) Bottom element: (n-1-i, n-1-i-j) Left element: (n-1-i-j, i) Rotation steps: Temporarily save the left element Move bottom → left Move right → bottom Move top → right Place saved left element → top 123456789101112131415class Solution {public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { int n = matrix.size(); for(int i = 0; i &lt; n / 2; i++){ for(int j = 0; j &lt; n - 2 * i - 1; j++){ int tmp = matrix[n-1-i-j][i]; matrix[n-1-i-j][i] = matrix[n-1-i][n-1-i-j]; matrix[n-1-i][n-1-i-j] = matrix[i+j][n-1-i]; matrix[i+j][n-1-i] = matrix[i][i+j]; matrix[i][i+j] = tmp; } } }}; Approach 2: Rotate by FlippingAnother simpler method is to rotate the matrix using flips: Flip the matrix upside down Flip along the main diagonal For the main diagonal, swap matrix[i][j] with matrix[j][i]. Only swap elements in the upper triangle where i &lt;= j (or lower triangle with j &lt;= i). 123456789101112131415161718class Solution {public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { int n = matrix.size(); // Flip vertically for (int i = 0; i &lt; n / 2; i++) { for (int j = 0; j &lt; n; j++) { swap(matrix[i][j], matrix[n-1-i][j]); } } // Flip along main diagonal for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; i; j++) { swap(matrix[i][j], matrix[j][i]); } } }}; 中文原文 [LeetCode hot 100] 48. 旋转图像题目链接 解法1：按圈旋转这个题做的时候就想到像轮转数组那样可以通过多次翻转来实现旋转矩阵的效果，不过一想，好像可以一圈一圈转，也可以实现O(1)空间复杂度。具体是怎样转的呢？我画了一个图： 对于某一个环，可以分为上、右、下、左四条，旋转时上边转到右边，右边转到下边，下边转到左边，左边转到上边。如果以边为单位转，需要一个O(N)大小的数组来保存。想要O(1)空间复杂度可以一个一个转，只需要弄明白四条边上对应位置的关系。 我们首先用一层循环来遍历旋转的圈。假如我们在从外到内第$i$个圈，$0&lt;i&lt;n/2$（如果n是奇数也对，因为最内圈就一个元素不用转）。 然后用第二层循环来遍历当前轮转的是元素。假如我们在对第$j$个元素进行轮转，$0&lt;j&lt;n-2i-1$，注意为什么要减1，是因为每条边不能包含最后一个元素，否则就多转了一次。 上边的元素位置是：$(i,i+j)$ 右边的元素位置是：$(i+j,n-1-i)$ 下边的元素位置是：$(n-1-i,n-1-i-j)$ 左边的元素位置是：$(n-1-i-j,i)$ 所以要做的就是先把左边的元素保存一下，然后把下边放到左边，右边放到下边，上边放到右边，最后把保存的左边元素放到上边。 完整代码如下： 123456789101112131415class Solution {public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { int n = matrix.size(); for(int i = 0; i &lt; n / 2; i++){ for(int j = 0; j &lt; n - 2 * i - 1; j++){ int tmp = matrix[n-1-i-j][i]; matrix[n-1-i-j][i] = matrix[n-1-i][n-1-i-j]; matrix[n-1-i][n-1-i-j] = matrix[i+j][n-1-i]; matrix[i+j][n-1-i] = matrix[i][i+j]; matrix[i][i+j] = tmp; } } }}; 解法2：翻转实现旋转后来看题解确实是可以用翻转实现旋转的。方法是首先对矩阵进行上下翻转，然后进行主对角线翻转，就完成了！ 只需要注意主对角线两侧对称的元素关系是$matrix[i][j]$和$matrix[j][i]$，即一维下标和二维下标互换。并且上三角元素$matrix[i][j]$的下标范围是$i\\leq j$，而下三角元素的下标范围是$j\\leq i$ 完整代码如下： 12345678910111213141516class Solution {public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { int n = matrix.size(); for (int i = 0; i &lt; n / 2; i++) { for (int j = 0; j &lt; n; j++) { swap(matrix[i][j], matrix[n-1-i][j]); } } for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; i; j++) { swap(matrix[i][j], matrix[j][i]); } } }};","link":"/2024/08/20/lc_48_%E6%97%8B%E8%BD%AC%E5%9B%BE%E5%83%8F/"},{"title":"&lt;Data Structure&#x2F;Algorithm&gt; 1.快速排序Quick Sort","text":"快速排序Quick SortFirst of all, quicksort is a recursive algorithm. The core idea is to select a pivot in a sequence, partition the elements into two groups such that all elements on the left are smaller than the pivot and all elements on the right are greater than the pivot, and then recursively apply the same procedure to both sides. So how do we actually perform this “partitioning into left and right”? The simplest approach works like this: Set up two pointers: a fast pointer and a slow pointer. The fast pointer is used for iteration, while the slow pointer marks a position. What position does the slow pointer mark? It’s the location where the next element smaller than the pivot should be placed. How is this position determined? Starting from the leftmost element, whenever we encounter an element smaller than the pivot, we place it at the left side and move the slow pointer one step to the right. Essentially, we put it at the current slow position, then increment slow++. But what about the original element at the slow position? We simply swap it with the element currently pointed to by the fast pointer (the one that is smaller than the pivot). By doing this throughout the iteration, all elements smaller than the pivot are moved to the left side. The remaining larger elements naturally end up on the right side. However, we still need to handle the pivot itself. Typically, the pivot is chosen as either the leftmost or rightmost element, and we skip it during the iteration. For example, if we choose the leftmost element as the pivot, we start the loop from the second element. If we choose the rightmost element, the loop stops at the second-to-last element. Finally, the pivot needs to be placed in the middle, and the slow pointer happens to be right at the correct position. We just swap the pivot with the slow pointer. There are two possible approaches here: Approach 1: Swap first, then increment slow. In this case, after the loop ends, slow points to the first element greater than the pivot (the leftmost element of the right partition). If the pivot was the left endpoint, swap it with slow - 1 so that the pivot ends up between the two partitions. If the pivot was the right endpoint, swap it directly with slow, placing the pivot correctly between the two partitions. Approach 2: Increment slow first, then swap. In this version, each swap is preceded by slow++, meaning that after the loop ends, slow points to the last element smaller than the pivot. The handling of pivot placement is similar to the first approach. Here is the C++ code: 123456789101112131415161718192021222324252627282930313233#include&lt;bits/stdc++.h&gt;#include&lt;vector&gt;using namespace std;int partition(vector&lt;int&gt; &amp;arr, int left, int right){ int pivot = arr[right]; int slow = left; for(int fast = left; fast &lt; right; fast++){ if(arr[fast] &lt; pivot){ int tmp = arr[slow]; arr[slow] = arr[fast]; arr[fast] = tmp; slow++; } } arr[right] = arr[slow]; arr[slow] = pivot; return slow;}void quickSort(vector&lt;int&gt; &amp;arr, int left, int right){ int p = partition(arr, left, right); quickSort(arr, left, p-1); quickSort(arr, p+1, right);}int main(){ vector&lt;int&gt; arr = {7, 9, 2, 5, 1}; quickSort(arr, 0, arr.size() - 1); for (int i = 0; i &lt; arr.size(); i++){ cout &lt;&lt; arr[i] &lt;&lt; &quot;,&quot;; }} 中文原文 事实上对于快速排序一直以来都是懵懵的，苦想后终于茅塞顿开。 首先，快速排序是一个递归的算法，核心思想是在一个序列中选择一个分界值（Pivot），将该序列中的元素划分为左右两部分，左边的元素均小于分界值，右边的元素大于分界值。然后对左右两边分别递归地执行此操作。 那么怎样执行这个“分成左右两边”的操作呢？目前最简洁的方法是这样的。 设立一个快指针fast，一个慢指针slow。快指针用于循环，慢指针用于指向一个位置。 指向的位置是什么呢？就是下一次遇到比pivot值小的元素时，应该把它填在哪里。 那么这个位置怎么确定呢，很简单，从序列最左边开始，每找到一个比pivot值小的元素就放到左边，然后往右挪一下就行了。对应到slow指针也就是每次往slow指针位置放，然后slow++。 那么原来位置上的元素怎么办呢？直接和当前这个快指针指向的元素，也就是那个比pivot值小的元素，互换位置就好了。 这样做，遍历一遍后，比pivot小的值都往左边不断地堆放，最后全在左边了。剩下的比pivot大的值自然就跑到右边去了。 但是还有一个pivot值没有处理，这个值往往是选择序列最左边或者最右边的元素，我们在刚刚的遍历中直接略过。也就是如果选了最左边的元素，一开始遍历就直接从第二个元素开始了。如果是最右边的元素，遍历的时候就到倒数第二个元素停止。 最后剩下的slow元素，很明显是要放到中间的。注意到这个时候slow指针正好就在中间，交换位置即可。这里有两种情况： 一种是每次交换后slow再++，也就是下一次放就是直接放到slow的位置。这种情况下遍历结束后的slow应该是指向第一个比pivot大的元素，也就是右边序列的最左端。如果pivot是左端点则需要和slow-1位置互换，这样把slow-1也就是最后一个比pivot小的值换到最前面，如果pivot是右端点则直接和slow互换，这样把第一个比pivot大的值换到最后面。 第二种是先slow++再交换，这样每一次交换前需要先把slow++挪到下一个位置。这种情况下遍历结束后的slow就是最后一个比pivot小的元素。对于两种pivot位置和第一种情况同理。 以下是C++代码： 12345678910111213141516171819202122232425262728293031323334#include&lt;bits/stdc++.h&gt;#include&lt;vector&gt;using namespace std;int partition(vector&lt;int&gt; &amp;arr, int left, int right){ int pivot = arr[right]; int slow = left; for(int fast = left; fast &lt; right; fast++){ if(arr[fast] &lt; pivot){ int tmp = arr[slow]; arr[slow] = arr[fast]; arr[fast] = tmp; slow++; } } arr[right] = arr[slow]; arr[slow] = pivot; return slow;}void quickSort(vector&lt;int&gt; &amp;arr, int left, int right){ int p = partition(arr, left, right); quickSort(arr, left, p-1); quickSort(arr, p+1, right);}int main(){ vector&lt;int&gt; arr = {7, 9, 2, 5, 1}; quickSort(arr, 0, arr.size() - 1); for (int i = 0; i &lt; arr.size(); i++){ cout &lt;&lt; arr[i] &lt;&lt; &quot;,&quot;; }}&lt;/details&gt;","link":"/2024/06/11/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8FQuick%20Sort/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode - 49. Group Anagrams","text":"LeetCode 49. Group AnagramsProblem Link A straightforward approach is to sort each string. Different anagrams will become identical after sorting, so we can use the sorted string as a key in a map. When inserting into the map: If the key does not exist, create a new group and record its position. If the key exists, append the current string to the corresponding group in the result. 1234567891011121314151617181920212223class Solution {public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) { vector&lt;vector&lt;string&gt;&gt; ans; map&lt;string, int&gt; posMap; int pos = 0; // Next group index for(auto&amp; str : strs){ string cur = str; sort(cur.begin(), cur.end()); if(posMap.find(cur) == posMap.end()){ posMap.emplace(cur, pos); vector&lt;string&gt; anagramList; anagramList.push_back(str); ans.push_back(anagramList); pos++; } else{ int curPos = posMap.find(cur)-&gt;second; ans[curPos].push_back(str); } } return ans; }}; 中文原文 [LeetCode hot 100] 49. 字母异位词分组题目链接 这道题比较直觉的做法就是先对每个词排序，因为不同异位词按照字母排序之后的异位词就是统一的了，因此将这个排序后的词作为map的键，查找map时如果存在这个键，就按照map中记录的位置去找这个键对应的异位词分组在返回结果中的位置，并且在这个异位词分组后面加上当前字符串。 1234567891011121314151617181920212223class Solution {public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) { vector&lt;vector&lt;string&gt;&gt; ans; map&lt;string, int&gt; posMap; int pos = 0;//分组的下一个下标 for(auto&amp; str : strs){ string cur = str; sort(cur.begin(), cur.end()); if(posMap.find(cur) == posMap.end()){ posMap.emplace(cur, pos); vector&lt;string&gt; anagramList; anagramList.push_back(str); ans.push_back(anagramList); pos++; } else{ int curPos = posMap.find(cur)-&gt;second; ans[curPos].push_back(str); } } return ans; }};","link":"/2024/07/24/lc_49_%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D%E5%88%86%E7%BB%84/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; A Complete Guide to Understanding Heaps 数据结构：堆 - 第k大","text":"A Complete Guide to Understanding HeapsWhat is a HeapA heap is a data structure in which elements are organized logically as a complete binary tree, but the underlying storage is implemented using an array. In other words, a tree structure is represented with an array. There are two types of heaps: Max-Heap: Every node is greater than or equal to its two children. Min-Heap: The opposite of a max-heap. Here we will use the max-heap as an example. The order of elements in the array corresponds to a level-order traversal of the heap. Since a heap is a complete binary tree, the relationship between a node and its children in the array can be determined as follows: Parent index: k Left child index: 2k + 1 Right child index: 2k + 2 Heap AdjustmentDue to the special structure of heaps, we must first understand the adjustment strategies. Heap adjustment transforms a non-heap structure into a valid heap. There are two types of adjustment: upward adjustment and downward adjustment. Upward AdjustmentAlso called “swim” or “bubble up.” It happens when a new element is inserted at the bottom of the heap (the end of the array). The new element needs to be moved to its correct position. This is done by comparing it with its parent and swapping if it is larger. The process repeats until the parent is larger, and the element stays in place. 12345678910void adjustUp(vector&lt;int&gt;&amp; heap, int child){ int parent = (child - 1) / 2; while(parent &gt;= 0 &amp;&amp; heap[child] &gt; heap[parent]){ int tmp = heap[parent]; heap[parent] = heap[child]; heap[child] = tmp; child = parent; parent = (child - 1) / 2; }} Downward AdjustmentAlso called “sink.” It happens when the root element changes. The root is compared with its two children. If the parent is not the largest, the largest child replaces it as the new parent. The process continues until the parent is greater than both children. 123456789101112131415161718192021void adjustDown(vector&lt;int&gt;&amp; heap, int parent){ int lchild = 2 * parent + 1; int rchild = lchild + 1; while(lchild &lt; heap.size()){ int largest = lchild; if(rchild &gt;= heap.size() || heap[lchild] &gt; heap[rchild]) largest = rchild; if(heap[parent] &gt; heap[largest]) break; int tmp = heap[parent]; heap[parent] = heap[largest]; heap[largest] = tmp; parent = largest; lchild = 2 * parent + 1; rchild = 2 * parent + 2; }} Inserting ElementsWith both adjustment strategies, inserting an element becomes simple: place it at the end of the heap and perform upward adjustment. 1234void heapInsert(vector&lt;int&gt;&amp; heap, int val){ heap.push_back(val); adjustUp(heap, heap.size() - 1);} Building a HeapIsn’t building a heap just inserting all elements one by one? 12345void buildHeap(vector&lt;int&gt;&amp; heap, vector&lt;int&gt;&amp; nums){ for(int i = 0; i &lt; nums.size(); i++){ heapInsert(heap, nums[i]); }} However, this approach performs many unnecessary operations. In fact, we only need to adjust downward starting from the last non-leaf node up to the root. The number of adjustments is logarithmic (O(log n)). 12345void buildHeap(vector&lt;int&gt;&amp; nums){ for(int i = (nums.size() - 1) / 2; i &gt;= 0; i--){ adjustDown(nums, i); }} This is amazing—it builds the heap directly in place. Starting from the second-to-last level, each subtree is adjusted to satisfy the max-heap property, then moving upward, ensuring the whole heap eventually satisfies the max-heap property. Deleting ElementsDeleting any element works the same way: swap it with the last element, shrink the heap size, and that element is effectively removed. The swapped element (originally at the end) now sits in the heap but may violate the heap property. Depending on its relation to its parent and children, it needs either upward or downward adjustment. In practice, we usually delete the root (maximum element). Since the new root is likely smaller than its children, we perform downward adjustment. Note: sometimes we only need to conceptually remove the root and place it at the end of the array without actually deleting it. In this case, we can use an index to represent the effective end of the heap. 123456void heapPop(vector&lt;int&gt;&amp; heap, int end){ int tmp = heap[end]; heap[end] = heap[0]; heap[0] = tmp; adjustDown(heap, 0);} Heap Application – k-th Largest ElementHeaps are often used for finding the k-th largest element. The basic idea is to repeatedly remove the maximum. After k removals, we obtain the k-th largest. 123456789int findKth(vector&lt;int&gt;&amp; nums, int k){ buildHeap(nums); int end = nums.size() - 1; for(int i = 0; i &lt; k; i++){ heapPop(nums, end); end--; } return end + 1;} However, this is somewhat inefficient since it requires building the heap and multiple adjustments. A better approach is to maintain a min-heap of size k. The root of this heap is the k-th largest element. For each new number, compare it with the root: If it is smaller, ignore it. If it is larger, replace the root and adjust downward. After processing all numbers, the heap root will be the k-th largest. 12345678910111213int findKth(vector&lt;int&gt;&amp; nums, int k){ vector&lt;int&gt; heap; for(int i = 0; i &lt; k; i++){ heapInsert(heap, nums[k]); // Note: heapInsert here should be written for a min-heap } for(int i = k; i &lt; nums.size(); i++){ if(nums[i] &gt; heap[0]){ heap[0] = nums[i]; // Replace root adjustDown(heap, 0); // Adjust downward } } return heap[0];} 中文原文 每次写关于堆的算法都要重新复习一遍，今天一定要搞清楚。 ### 什么是堆 堆是一种数据结构，其中的数据以完全二叉树的逻辑组织，但是存储数据的结构使用的是数组。也就是说，要用数组表示一个树的结构。堆分为两种： 大根堆：树中任何一个节点大于或等于他的两个孩子节点。 小根堆：与大根堆相反。 我们这里以大根堆为例。 堆在数组中存放的顺序是层序，也就是说先存第一层，再存第二层，……由于堆是完全二叉树，所以在数组中存放时，每个节点与其左右孩子节点的位置关系都是可以确定的。 父节点位置：k 左孩子位置：2k+1 右孩子位置：2k+2 堆的调整由于堆的结构特殊性，所以先要了解堆的调整策略。堆的调整是将不符合堆的结构调整成符合堆的数据结构，分为向上调整和向下调整。 向上调整向上调整又叫上浮，发生在堆底（也就是末尾）插入新元素的时候，这时要把插入的元素调整到正确的位置，具体做法是确定父节点的位置，与之比较，如果比父节点大就和父节点交换，直到比父节点小，被管住了，就老实呆在那里了。代码如下 12345678910void adjustUp(vector&lt;int&gt;&amp; heap, int child){ int parent = (child - 1) / 2; while(parent &gt;= 0 &amp;&amp; heap[child] &gt; heap[parent]){ int tmp = heap[parent]; heap[parent] = heap[child]; heap[child] = tmp; child = parent; parent = (child - 1) / 2; }} 向下调整向下调整又叫下沉，发生在堆顶元素改变时。此时需要堆顶元素与两个孩子比较，假如父节点元素不是最大的，说明父节点管不住孩子了，需要将其中最大的孩子扶持为新的堆顶，如此循环直到父节点比他的两个孩子都大。 123456789101112131415161718192021void adjustDown(vector&lt;int&gt;&amp; heap, int parent){ int lchild = 2 * parent + 1; int rchild = lchild + 1; while(lchild &lt; heap.size()){ int largest = lchild; if(rchild &gt;= heap.size() || heap[lchild] &gt; heap[rchild]) largest = rchild; if(heap[parent] &gt; heap[largest]) break; int tmp = heap[parent]; heap[parent] = heap[largest]; heap[largest] = tmp; parent = largest; lchild = 2 * parent + 1; rchild = 2 * parent + 2; }} 插入元素现在有了两种调整堆的方法，很容易就能插入元素。把元素放到堆底并向上调整就行。 1234void heapInsert(vector&lt;int&gt;&amp; heap, int val){ heap.push_back(val); adjustUp(heap, heap.size() - 1);} 堆的创建那创建堆不就是一个一个元素往堆里面插入吗？ 12345void buildHeap(vector&lt;int&gt;&amp; heap, vector&lt;int&gt;&amp; nums){ for(int i = 0; i &lt; nums.size(); i++){ heapInsert(heap, nums[i]); }} 但是这样其实多做了很多无意义的操作，事实上，只要从孩子一步一步往父节点调整就够了，调整次数为logn，即： 12345void buildHeap(vector&lt;int&gt;&amp; nums){ for(int i = (nums.size() - 1) / 2; i &gt;= 0; i--){ adjustDown(nums, i); }} 太神奇了，这甚至是在原数组上就进行了，相当于对于倒数第二层的节点，首先调整以他们为堆顶的子堆，满足大根堆的性质（使用向下调整），然后调整他们父母为顶的子堆，满足大根堆的性质，直到调整到整个堆的顶部，就能保证整个堆满足了大根堆的性质。 删除元素删除任何一个元素都是一样的，只需要把这个元素放到最后，然后把堆的大小一缩，诶，那个元素就被挡在外面了。那么原本末尾的元素呢，就放到删掉的元素的原本的位置，也就是位置互换了。互换之后末尾的元素还在堆内，但是不满足堆的性质了，所以需要根据和父节点、两个子节点的大小关系判断该选择上浮还是下沉。但是一般我们常用的就是删除堆顶，那堆顶都删没了，新进来的元素肯定没有第二层的大呀，所以需要下沉调整。 这里注意，有的时候我们只是需要形式上把堆顶拿出来，放在后面，并不需要真的把它从这个数组中删掉，只是不在堆中了。这时我们可以使用一个元素来代表堆的末尾指针。 123456void heapPop(vector&lt;int&gt;&amp; heap, int end){ int tmp = heap[end]; heap[end] = heap[0]; heap[0] = tmp; adjustDown(heap, 0);} 堆的应用-第k大元素堆在找第k大这种问题上应用比较多。具体就是使用我们的删除操作，每轮删掉一个最大的，这样删k轮就找到第k大了。 123456789int findKth(vector&lt;int&gt;&amp; nums, int k){ buildHeap(nums); int end = nums.size() - 1; for(int i = 0; i &lt; k; i++){ heapPop(nums, end); end--; } return end + 1;} 但是其实这样是绕了弯路的，因为需要首先建堆，然后一次一次地调整。如果我们换一种思路呢？我们可以用大根堆维护所有的元素，那我们也可以用一个小根堆维护前k大的元素，这个时候小根堆的堆顶就是第k大的元素，每来一个数就和堆顶比较一下，如果比堆顶小，那么说明数组中已经发现了k个比堆顶元素大的数，那么堆顶显然就不可能是前k大的元素之一了，应该被踢掉。如此遍历整个数组，就能得到整个数组前k大的数构成的小根堆，堆顶就是第k大的元素。 12345678910111213int findKth(vector&lt;int&gt;&amp; nums, int k){ vector&lt;int&gt; heap; for(int i = 0; i &lt; k; i++){ heapInsert(heap, nums[k]); //注意这里的heapInsert应该根据小根堆来写 } for(int i = k; i &lt; nums.size(); i++){ if(nums[i] &gt; heap[0]){ heap[0] = nums[i]; //替换掉堆顶 adjustDown(heap, 0); //向下调整 } } return heap[0];}","link":"/2024/06/19/%E6%88%91%E4%B8%80%E5%AE%9A%E8%A6%81%E5%AD%A6%E4%BC%9A%E3%80%90%E5%A0%86%E3%80%91/"},{"title":"&lt;Data Structures&#x2F;Algorithms&gt; LeetCode 42. Trapping Rain Water","text":"LectCode 42. Trapping Rain WaterProblem Link This is a classic and highly popular problem that tests your thinking skills. The key is to understand how “trapping water” actually works. The difficulty lies in the fact that a large container may contain smaller containers—nested pits. We must avoid double-counting or missing any water. Consider a pit with smaller pits and steps inside it. How do we calculate the water it can trap? Any pit has three components: the left wall, the right wall, and the bottom in between. To avoid double counting, we divide pits into layers. As shown in the figure, we need to record the left walls so that when we reach a right wall, we can compute the trapped water correctly. Do we need to record every left column? Not necessarily. Observing the diagram, when we reach the fourth column, a small pit is already formed. We can calculate the water for this small pit and then continue calculating from the higher of the left and right walls, skipping recalculating the small pit. This structure is well-suited for a monotonic stack. The stack maintains a decreasing order from bottom to top, ensuring only potential walls are kept. For example, column 3 becomes the bottom of a pit when column 4 is taller, and it should not be considered again because it has already contributed to the trapped water. The stack process identifies pits and discards the bottoms after calculation. For this example, the process is: Step Operation Stack Explanation 1 Push 1 1 2 2 &lt; top, push 2 1,2 Possible wall for sub-pit 3 3 &lt; top, push 3 1,2,3 Possible wall for sub-pit 4 4 &gt; top, pop and calculate with 2 (new top) 1,2 Area shown in cyan 5 4 &lt; top, push 4 1,2,4 Possible wall 6 5 &lt; top, push 5 1,2,4,5 Same 7 6 &gt; top, pop and calculate with 2 (new top) 1,2,4 8 6 &lt; top, push 6 1,2,4,6 9 7 &gt; top, pop and calculate with 4 (new top) 1,2,4 Area shown in light purple 10 7 &gt; top, pop and calculate with 2 (new top) 1,2 Area shown in purple 11 7 &gt; top, pop and calculate with 1 (new top) 1 Area shown in dark blue 12 7 &lt; top, push 7 1,7 13 End traversal Thinking of it as filling cement helps: fill small pits first, then the large pit. The small pit above is already filled, so the large pit just fills over it. Complete code is as follows: 123456789101112131415161718class Solution {public: int trap(vector&lt;int&gt;&amp; height) { stack&lt;int&gt; st; int ans = 0; for(int i = 0; i &lt; height.size(); i++){ while(!st.empty() &amp;&amp; height[i] &gt; height[st.top()]){ int bottom = st.top(); st.pop(); if(st.empty()) break; int left = st.top(); ans += (i - left - 1) * (min(height[left], height[i]) - height[bottom]); } st.push(i); } return ans; }}; 中文原文 [LeetCode hot 100] 42. 接雨水题目链接 这个题实在是太经典了，存在感太强了，我认为也是很考验思维的一个题，关键在于要想明白“接水”到底是怎么一回事。 这个题的难点在于，大的容器里可能有小的容器，大坑套小坑，既不能漏算也不能重复算。 这是一个坑，坑里还有小坑，还有阶梯，应该怎么算这个坑能接多少水呢？我们注意到，任何一个坑都有三个组成部分：左壁，右壁，以及中间的底。为了避免重算，我们把坑分成几层。就像上面这个图一样。我们需要记录左壁的结构，这样才能在碰到右壁时找到对应的左壁进行计算。那么左边的柱子需要全部记录下来吗？其实并不是的。观察上面这个图，当来到第四根柱子时，左边已经产生了一个小坑，这个时候就可以计算这个小坑的面积，然后后面就不需要再计算这个小坑的面积，而是从左右壁比较高的一个往上继续算。 这种结构很适合用单调栈来解决，单调栈从栈底到栈顶保持递减，这样可以保证我们栈里留得都是可能作为“壁”的柱子，像图中第3根那种柱子，在碰到第四根更高的柱子，就变成了一个“坑底”，在后续的计算中就不应再考虑，因为他既不影响后面的计算结果（因为自己这个坑已经算过了，更大的坑就要从现在这个坑壁往上算了），也不可能作为后面的坑壁。因此，单调栈维护的过程就是在识别坑，并且算完后把坑底扔掉。对于图中这个情形，过程是： 步骤 操作 栈 解释 1 1号入栈 1 2 2比栈顶矮，2入栈 1,2 2可能作为子坑的壁 3 3比栈顶矮，3入栈 1,2,3 3也可能作为子坑的壁 4 4比栈顶高，出栈，同时计算4和2（新栈顶）之间的容积 1,2 对应图中青绿色面积 5 4比栈顶矮，4入栈 1,2,4 4可能作为坑壁 6 5比栈顶矮，5入栈 1,2,4,5 同上 7 6比栈顶高，出栈，同时计算6和2（新栈顶）之间的容积 1,2,4 8 6比栈顶矮，入栈 1,2,4,6 9 7比栈顶高，出栈，同时计算7和4（新栈顶）之间的容积 1,2,4 对应图中浅紫色面积 10 7比栈顶高，出栈，同时计算7和2（新栈顶）之间的容积 1,2 对应紫色面积 11 7比栈顶高，出栈，同时计算7和1（新栈顶）之间的容积 1 对应深蓝色面积 12 7比栈顶矮，7入栈 1,7 13 遍历结束 结合图来看就可以理解了，其实这个问题想成填水泥更好，小坑里面填完了水泥，大坑再填就不用填小坑了，从小坑上面接着填就行，就是这个道理。 完整代码如下： 123456789101112131415161718class Solution {public: int trap(vector&lt;int&gt;&amp; height) { stack&lt;int&gt; st; int ans = 0; for(int i = 0; i &lt; height.size(); i++){ while(!st.empty() &amp;&amp; height[i] &gt; height[st.top()]){ int bottom = st.top(); st.pop(); if(st.empty()) break; int left = st.top(); ans += (i - left - 1) * (min(height[left], height[i]) - height[bottom]); } st.push(i); } return ans; }};","link":"/2024/08/20/lc_42_%E6%8E%A5%E9%9B%A8%E6%B0%B4/"}],"tags":[{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"optimization","slug":"optimization","link":"/tags/optimization/"},{"name":"Programming Languages","slug":"Programming-Languages","link":"/tags/Programming-Languages/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"graph","slug":"graph","link":"/tags/graph/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"algorith","slug":"algorith","link":"/tags/algorith/"},{"name":"binary search","slug":"binary-search","link":"/tags/binary-search/"},{"name":"gpu","slug":"gpu","link":"/tags/gpu/"},{"name":"cuda","slug":"cuda","link":"/tags/cuda/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"postgresql","slug":"postgresql","link":"/tags/postgresql/"},{"name":"index","slug":"index","link":"/tags/index/"},{"name":"predict","slug":"predict","link":"/tags/predict/"},{"name":"vector database","slug":"vector-database","link":"/tags/vector-database/"},{"name":"cpu-gpu co-design","slug":"cpu-gpu-co-design","link":"/tags/cpu-gpu-co-design/"},{"name":"agent","slug":"agent","link":"/tags/agent/"},{"name":"pdf","slug":"pdf","link":"/tags/pdf/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"STL","slug":"STL","link":"/tags/STL/"},{"name":"dp","slug":"dp","link":"/tags/dp/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"variable","slug":"variable","link":"/tags/variable/"},{"name":"copy","slug":"copy","link":"/tags/copy/"},{"name":"two-pointers","slug":"two-pointers","link":"/tags/two-pointers/"},{"name":"deep learning","slug":"deep-learning","link":"/tags/deep-learning/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"distribution shift","slug":"distribution-shift","link":"/tags/distribution-shift/"},{"name":"mlsys","slug":"mlsys","link":"/tags/mlsys/"},{"name":"distributed system","slug":"distributed-system","link":"/tags/distributed-system/"},{"name":"backtrack","slug":"backtrack","link":"/tags/backtrack/"},{"name":"greenplum","slug":"greenplum","link":"/tags/greenplum/"},{"name":"python37","slug":"python37","link":"/tags/python37/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"slide-window","slug":"slide-window","link":"/tags/slide-window/"},{"name":"hash","slug":"hash","link":"/tags/hash/"},{"name":"binary-tree","slug":"binary-tree","link":"/tags/binary-tree/"},{"name":"sort","slug":"sort","link":"/tags/sort/"},{"name":"heap","slug":"heap","link":"/tags/heap/"}],"categories":[{"name":"machine learning","slug":"machine-learning","link":"/categories/machine-learning/"},{"name":"Programming Languages","slug":"Programming-Languages","link":"/categories/Programming-Languages/"},{"name":"Dive into Deep Learning-Notes","slug":"machine-learning/Dive-into-Deep-Learning-Notes","link":"/categories/machine-learning/Dive-into-Deep-Learning-Notes/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"gpu","slug":"gpu","link":"/categories/gpu/"},{"name":"db_index","slug":"db-index","link":"/categories/db-index/"},{"name":"vector_db","slug":"vector-db","link":"/categories/vector-db/"},{"name":"agent","slug":"agent","link":"/categories/agent/"},{"name":"optimization","slug":"machine-learning/Dive-into-Deep-Learning-Notes/optimization","link":"/categories/machine-learning/Dive-into-Deep-Learning-Notes/optimization/"},{"name":"Programming Language","slug":"Programming-Language","link":"/categories/Programming-Language/"},{"name":"C++","slug":"Algorithm/C","link":"/categories/Algorithm/C/"},{"name":"python","slug":"Algorithm/python","link":"/categories/Algorithm/python/"},{"name":"C++","slug":"gpu/C","link":"/categories/gpu/C/"},{"name":"deep learning","slug":"machine-learning/deep-learning","link":"/categories/machine-learning/deep-learning/"},{"name":"predictive","slug":"db-index/predictive","link":"/categories/db-index/predictive/"},{"name":"mlsys","slug":"mlsys","link":"/categories/mlsys/"},{"name":"ubuntu","slug":"ubuntu","link":"/categories/ubuntu/"},{"name":"C++","slug":"Programming-Language/C","link":"/categories/Programming-Language/C/"},{"name":"job","slug":"Algorithm/C/job","link":"/categories/Algorithm/C/job/"},{"name":"job","slug":"Algorithm/python/job","link":"/categories/Algorithm/python/job/"},{"name":"cuda","slug":"gpu/C/cuda","link":"/categories/gpu/C/cuda/"},{"name":"LLM","slug":"machine-learning/deep-learning/LLM","link":"/categories/machine-learning/deep-learning/LLM/"}],"pages":[{"title":"","text":"CNN: Convolution?Now I am at chapter convolutional neural network. There is a formula with many subscripts: What does it mean? Well, let’s put it in a graph.","link":"/Archived/CNN%20Convolution.html"},{"title":"","text":"使用vue和elementui遇到的各种坑正则表达式报错一般是因为其中的反斜杠解析错误，在后面加上 1// eslint-disable-line 这个注释就好 el-form几种表单验证方式https://blog.csdn.net/weixin_45046532/article/details/137624361 常用表单域验证正则匹配https://blog.csdn.net/2401_84092423/article/details/137700320 嵌套el-form-itemhttps://blog.csdn.net/weixin_69670563/article/details/135880729 el-form里出现一个item包含多个输入，怎样进行表单域验证？邮箱验证1/^\\\\s*\\\\w+(?:\\\\.{0,1}[\\\\w-]+)*@[a-zA-Z0-9]+(?:[-.][a-zA-Z0-9]+)*\\\\.[a-zA-Z]+\\\\s*$/ /^\\s*\\w+(?:\\.{0,1}[\\w-]+)@[a-zA-Z0-9]+(?:[-.][a-zA-Z0-9]+)\\.[a-zA-Z]+\\s*$/ 87558353","link":"/Archived/%E4%BD%BF%E7%94%A8vue%E5%92%8Celementui%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E5%9D%91.html"},{"title":"","text":"MySQL一些底层的东西开这个文章的初衷是在研究MySQL的一些底层原理时，感觉网上的博客写得太过抽象，虽然我语文也没那么好，但是相信还是比他们略好一点的。所以这个文章打算用来记录MySQL底层的一些原理。 MySQL总体架构MySQL官方给出的MySQL架构图是这样的。主要由5个部分组成：缓存区，解析器，预处理器， Innodb存储引擎","link":"/Archived/MySQL%E4%B8%80%E4%BA%9B%E5%BA%95%E5%B1%82%E7%9A%84%E4%B8%9C%E8%A5%BF.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/Archived/hello-world.html"},{"title":"Python Interview-2. List and Dict","text":"[Python Interview]List and DictListStorageThe elements of a list are stored respectively and separately in the memory. However, their addresses are stored together as a sequence list. It’s kind of like a pointer array in C or C++. When user","link":"/Archived/Python-Interview-2.-List-and-Dict.html"},{"title":"about","text":"I am Zhaorui Ding, currently pursuing MSCS at Georgia Institute of Technology (Atlanta Campus). I am expected to graduate in Dec 2026 - May 2027. Education Background 2027: Master of Science in Computer Science, Georgia Institute of Technology 2024: Bachelor of Engineering in Computer Science and Technology, Huazhong University of Science and Technology GPA: 3.83/4.00 2020: Tsinghua University High School Professional Experience Jun 2025 - Aug 2025: Software Engineer Intern, Tencent, WXG (WeChat Group). Developed back end for WeChat. Feb 2025 - Jun 2025: Software Engineer Intern, SLB. Developed back end for Drillplan Web App Sep 2024 - Feb 2025: Software Engineer Intern, Microsoft. Developed backend for Bing Image feed. Cool products that I contributed to during internships WeChat Public Account Translation Bing Image Feed Bing Image Feed Publication Arbiter: Joint Tuner for Partitioning and Customized Indexing with Trusted Bayesian Optimization. Information Processing &amp; Management (minor revision) Fengrui Liu, Zhaorui Ding, Hua Wang, Rukai Wei, Zhongcong Mo, Ke Zhou, Yu Liu Research Experience Research Assistant 03/2023 - 09/2023 Intelligent Data Storage and Management Laboratory, Wuhan National Laboratory for Optoelectronics Supervisor: Hua Wang Research Assistant 03/2023 - 09/2023 Department of AI for Biology, Shanghai Artificial Intelligence Laboratory","link":"/about/index.html"}]}